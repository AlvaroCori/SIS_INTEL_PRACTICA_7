{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBibliografy\\nOpen a CSV\\nhttps://code.tutsplus.com/es/tutorials/how-to-read-and-write-csv-files-in-python--cms-29907\\nSave in a dataframe pandas\\nhttps://realpython.com/pandas-python-explore-dataset/\\nAleatory values for a list \\nttps://www.iteramos.com/pregunta/17907/la-mejor-manera-de-aleatorizar-una-lista-de-cuerdas-en-python\\n\\nexcel\\nhttps://gonzalezgouveia.com/como-exportar-data-frames-de-pandas-a-csv-o-excel-en-python/\\nhttps://www.delftstack.com/es/howto/python-pandas/pandas-remove-index/#:~:text=Si%20queremos%20eliminar%20la%20columna,en%20el%20m%C3%A9todo%20reset_index()%20\\ndataframe  \\nhttps://www.codigopiton.com/como-crear-un-dataframe-con-pandas-y-python/\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "'''\n",
    "Bibliografy\n",
    "Open a CSV\n",
    "https://code.tutsplus.com/es/tutorials/how-to-read-and-write-csv-files-in-python--cms-29907\n",
    "Save in a dataframe pandas\n",
    "https://realpython.com/pandas-python-explore-dataset/\n",
    "Aleatory values for a list \n",
    "ttps://www.iteramos.com/pregunta/17907/la-mejor-manera-de-aleatorizar-una-lista-de-cuerdas-en-python\n",
    "\n",
    "excel\n",
    "https://gonzalezgouveia.com/como-exportar-data-frames-de-pandas-a-csv-o-excel-en-python/\n",
    "https://www.delftstack.com/es/howto/python-pandas/pandas-remove-index/#:~:text=Si%20queremos%20eliminar%20la%20columna,en%20el%20m%C3%A9todo%20reset_index()%20\n",
    "dataframe  \n",
    "https://www.codigopiton.com/como-crear-un-dataframe-con-pandas-y-python/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Temperature', 'L', 'R', 'A_M', 'Color', 'Spectral_Class', 'Type']\n",
      "['3453', '0.000621', '0.0773', '17.08', 'Red', 'M', '0']\n",
      "['12098', '689', '7.01', '0.02', 'Blue-white', 'A', '3']\n",
      "['2731', '0.000437', '0.0856', '18.09', 'Red', 'M', '0']\n",
      "['37800', '202900', '6.86', '-4.56', 'Blue', 'O', '3']\n",
      "['8570', '0.00081', '0.0097', '14.2', 'Blue white', 'A', '2']\n",
      "['3605', '126000', '1124', '-10.81', 'Red', 'M', '5']\n",
      "['8052', '8.7', '1.8', '2.42', 'Whitish', 'A', '3']\n",
      "['3574', '200000', '89', '-5.24', 'Red', 'M', '4']\n",
      "['8829', '537493', '1423', '-10.73', 'White', 'A', '5']\n",
      "['3625', '74000', '876', '-10.25', 'Red', 'M', '5']\n",
      "['17383', '342900', '30', '-6.09', 'Blue', 'O', '4']\n",
      "['3419', '0.000245', '0.126', '17.56', 'Red', 'M', '0']\n",
      "['3752', '209000', '955', '-11.24', 'Red', 'M', '5']\n",
      "['9383', '342940', '98', '-6.98', 'Blue', 'O', '4']\n",
      "['3142', '0.00132', '0.258', '14.12', 'Red', 'M', '1']\n",
      "['17200', '0.00098', '0.015', '12.45', 'Blue White', 'B', '2']\n",
      "['3091', '0.0081', '0.24', '11.43', 'Red', 'M', '1']\n",
      "['26373', '198000', '39', '-5.83', 'Blue', 'O', '4']\n",
      "['32460', '173800', '6.237', '-4.36', 'Blue', 'O', '3']\n",
      "['2621', '0.0006', '0.098', '12.81', 'Red', 'M', '1']\n",
      "['28700', '16790', '6.4', '-4.09', 'Blue-white', 'B', '3']\n",
      "['2914', '0.000631', '0.116', '18.39', 'Red', 'M', '0']\n",
      "['23092', '0.00132', '0.0104', '10.18', 'Blue', 'B', '2']\n",
      "['2835', '0.00034', '0.0918', '16.96', 'Red', 'M', '0']\n",
      "['3341', '0.0056', '0.057', '16.23', 'Red', 'M', '0']\n",
      "['3598', '0.0027', '0.67', '13.667', 'Red', 'M', '1']\n",
      "['19920', '0.00156', '0.0142', '11.34', 'Blue', 'B', '2']\n",
      "['18290', '0.0013', '0.00934', '12.78', 'Blue', 'B', '2']\n",
      "['16500', '0.013', '0.014', '11.89', 'Blue White', 'B', '2']\n",
      "['2871', '0.00072', '0.12', '19.43', 'Red', 'M', '0']\n",
      "['4526', '0.153', '0.865', '6.506', 'yellowish', 'K', '3']\n",
      "['3441', '0.039', '0.351', '11.18', 'Red', 'M', '1']\n",
      "['10012', '552', '5.856', '0.013', 'Blue-white', 'A', '3']\n",
      "['3257', '0.0024', '0.46', '10.73', 'Red', 'M', '1']\n",
      "['15680', '0.00122', '0.0114', '11.92', 'Blue', 'B', '2']\n",
      "['26000', '316000', '1679', '-9.1', 'Blue', 'B', '5']\n",
      "['12100', '120000', '708.9', '-7.84', 'Blue-white', 'B', '5']\n",
      "['3535', '195000', '1546', '-11.36', 'Red', 'M', '5']\n",
      "['2774', '0.00036', '0.118', '17.39', 'Red', 'M', '0']\n",
      "['3450', '263000', '1349', '-11.75', 'Red', 'M', '5']\n",
      "['17120', '235000', '83', '-6.89', 'Blue', 'O', '4']\n",
      "['25070', '14500', '5.92', '-3.98', 'Blue-white', 'B', '3']\n",
      "['25390', '223000', '57', '-5.92', 'Blue', 'O', '4']\n",
      "['3100', '0.008', '0.31', '11.17', 'Red', 'M', '1']\n",
      "['25000', '0.056', '0.0084', '10.58', 'Blue White', 'B', '2']\n",
      "['3324', '0.0034', '0.34', '12.23', 'Red', 'M', '1']\n",
      "['2840', '0.00065', '0.11', '16.98', 'Red', 'M', '0']\n",
      "['3780', '200000', '1324', '-10.7', 'Red', 'M', '5']\n",
      "['2890', '0.0034', '0.24', '13.46', 'Red', 'M', '1']\n",
      "['12912', '0.00071', '0.00945', '12.83', 'Blue white', 'B', '2']\n",
      "['9320', '29', '1.91', '1.236', 'Blue-white', 'A', '3']\n",
      "['33750', '220000', '26', '-6.1', 'Blue', 'B', '4']\n",
      "['3042', '0.0005', '0.1542', '16.6', 'Red', 'M', '0']\n",
      "['2600', '0.0003', '0.102', '18.7', 'Red', 'M', '0']\n",
      "['3523', '0.0054', '0.319', '12.43', 'Red', 'M', '1']\n",
      "['3432', '0.00067', '0.19', '16.94', 'Red', 'M', '0']\n",
      "['3600', '0.0029', '0.51', '10.69', 'Red', 'M', '1']\n",
      "['14732', '0.00011', '0.00892', '12.89', 'white', 'F', '2']\n",
      "['3660', '363000', '1673', '-11.92', 'Red', 'M', '5']\n",
      "['3575', '123000', '45', '-6.78', 'Red', 'M', '4']\n",
      "['2637', '0.00073', '0.127', '17.22', 'Red', 'M', '0']\n",
      "['3607', '0.00023', '0.38', '10.34', 'Red', 'M', '1']\n",
      "['13089', '788', '5.992', '-0.12', 'Blue-white', 'A', '3']\n",
      "['19360', '0.00125', '0.00998', '11.62', 'Blue', 'B', '2']\n",
      "['3834', '272000', '1183', '-9.2', 'Red', 'M', '5']\n",
      "['3345', '0.021', '0.273', '12.3', 'Red', 'M', '1']\n",
      "['3600', '240000', '1190', '-7.89', 'Red', 'M', '5']\n",
      "['3511', '0.00064', '0.109', '17.12', 'Red', 'M', '0']\n",
      "['14982', '0.00118', '0.0113', '12.23', 'Blue', 'B', '2']\n",
      "['2600', '0.0004', '0.096', '17.4', 'Red', 'M', '0']\n",
      "['37882', '294903', '1783', '-7.8', 'Blue', 'O', '5']\n",
      "['5587', '0.819', '0.99', '5.03', 'yellow-white', 'F', '3']\n",
      "['3531', '0.00093', '0.0976', '19.94', 'Red', 'M', '0']\n",
      "['19923', '152000', '73', '-5.69', 'Blue', 'O', '4']\n",
      "['21738', '748890', '92', '-7.346', 'Blue', 'O', '4']\n",
      "['3323', '0.00043', '0.0912', '17.16', 'Red', 'M', '0']\n",
      "['18340', '0.00134', '0.0124', '11.22', 'Blue', 'B', '2']\n",
      "['11900', '0.00067', '0.00898', '11.38', 'Blue white', 'B', '2']\n",
      "['12990', '8.50E-05', '0.00984', '12.23', 'Yellowish White', 'F', '2']\n",
      "['4015', '282000', '1534', '-11.39', 'Red', 'K', '5']\n",
      "['3500', '138000', '1420', '-8.18', 'Red', 'M', '5']\n",
      "['3304', '0.0085', '0.18', '13.2', 'Red', 'M', '1']\n",
      "['10930', '783930', '25', '-6.224', 'Blue', 'O', '4']\n",
      "['7282', '131000', '24', '-7.22', 'Blue', 'O', '4']\n",
      "['10980', '0.00074', '0.0087', '11.19', 'Blue White', 'B', '2']\n",
      "['16787', '246730', '62', '-6.35', 'Blue', 'O', '4']\n",
      "['33421', '352000', '67', '-5.79', 'Blue', 'O', '4']\n",
      "['3200', '195000', '17', '-7.22', 'Red', 'M', '4']\n",
      "['3570', '320000', '1480', '-7.58', 'Red', 'M', '5']\n",
      "['7740', '0.00049', '0.01234', '14.02', 'White', 'A', '2']\n",
      "['14060', '1092', '5.745', '-2.04', 'Blue-white', 'A', '3']\n",
      "['6380', '1.35', '0.98', '2.93', 'yellow-white', 'F', '3']\n",
      "['3463', '0.0027', '0.675', '14.776', 'Red', 'M', '1']\n",
      "['3180', '0.001', '0.35', '11.76', 'Red', 'M', '1']\n",
      "['2778', '0.000849', '0.112', '19.45', 'Red', 'M', '0']\n",
      "['2861', '0.00019', '0.0899', '16.71', 'Red', 'M', '0']\n",
      "['3484', '0.000551', '0.0998', '16.67', 'Red', 'M', '0']\n",
      "['23000', '127000', '36', '-5.76', 'Blue', 'O', '4']\n",
      "['4287', '630000', '1315', '-9.2', 'Orange', 'K', '5']\n",
      "['3462', '0.0053', '0.148', '11.47', 'Red', 'M', '1']\n",
      "['36108', '198000', '10.2', '-4.4', 'Blue', 'O', '3']\n",
      "['11250', '672', '6.98', '-2.3', 'Blue-white', 'A', '3']\n",
      "['12984', '0.00088', '0.00996', '11.23', 'Blue White', 'B', '2']\n",
      "['2817', '0.00098', '0.0911', '16.45', 'Red', 'M', '0']\n",
      "['2945', '0.00032', '0.093', '18.34', 'Red', 'M', '0']\n",
      "['9373', '424520', '24', '-5.99', 'Blue', 'O', '4']\n",
      "['7220', '0.00017', '0.011', '14.23', 'White', 'F', '2']\n",
      "['5936', '1.357', '1.106', '4.46', 'yellow-white', 'F', '3']\n",
      "['38940', '374830', '1356', '-9.93', 'Blue', 'O', '5']\n",
      "['9892', '593900', '80', '-7.262', 'Blue', 'O', '4']\n",
      "['40000', '813000', '14', '-6.23', 'Blue', 'O', '4']\n",
      "['3212', '0.0016', '0.378', '12.854', 'Red', 'M', '1']\n",
      "['18734', '224780', '46', '-7.45', 'Blue', 'O', '4']\n",
      "['2831', '0.000231', '0.0915', '16.21', 'Red', 'M', '0']\n",
      "['9235', '404940', '1112', '-11.23', 'White', 'A', '5']\n",
      "['27739', '849420', '1252', '-7.59', 'Blue-white', 'B', '5']\n",
      "['3324', '0.0065', '0.471', '12.78', 'Red', 'M', '1']\n",
      "['3610', '132000', '1522', '-10.86', 'Red', 'M', '5']\n",
      "['13340', '0.00109', '0.0116', '12.9', 'Blue', 'B', '2']\n",
      "['5300', '0.59', '0.91', '5.49', 'yellow-white', 'F', '3']\n",
      "['3365', '340000', '23', '-6.2', 'Red', 'M', '4']\n",
      "['7100', '0.00029', '0.012', '14.09', 'White-Yellow', 'F', '2']\n",
      "['14245', '231000', '42', '-6.12', 'Blue', 'O', '4']\n",
      "['10574', '0.00014', '0.0092', '12.02', 'White', 'F', '2']\n",
      "['15276', '1136', '7.2', '-1.97', 'Blue-white', 'B', '3']\n",
      "['3095', '0.00019', '0.492', '10.87', 'Red', 'M', '1']\n",
      "['24630', '363000', '63', '-5.83', 'Blue', 'O', '4']\n",
      "['3625', '184000', '84', '-6.74', 'Red', 'M', '4']\n",
      "['3459', '100000', '1289', '-10.7', 'Red', 'M', '5']\n",
      "['3749', '550000', '1648', '-8.05', 'Orange', 'M', '5']\n",
      "['3692', '0.00367', '0.47', '10.8', 'Red', 'M', '1']\n",
      "['7723', '0.00014', '0.00878', '14.81', 'White', 'A', '2']\n",
      "['3750', '283000', '1260', '-7.63', 'Red', 'M', '5']\n",
      "['2650', '0.0006', '0.14', '11.782', 'Red', 'M', '1']\n",
      "['2889', '0.000352', '0.0973', '16.93', 'Red', 'M', '0']\n",
      "['8930', '0.00056', '0.0095', '13.78', 'white', 'A', '2']\n",
      "['14100', '0.00067', '0.0089', '12.17', 'Blue White', 'B', '2']\n",
      "['24145', '382993', '1494', '-8.84', 'Blue-white', 'B', '5']\n",
      "['7230', '8.00E-05', '0.013', '14.08', 'Pale yellow orange', 'F', '2']\n",
      "['2800', '0.0002', '0.16', '16.65', 'Red', 'M', '0']\n",
      "['8500', '0.0005', '0.01', '14.5', 'White', 'A', '2']\n",
      "['2856', '0.000896', '0.0782', '19.56', 'Red', 'M', '0']\n",
      "['3600', '320000', '29', '-6.6', 'Red', 'M', '4']\n",
      "['12675', '452000', '83', '-5.62', 'Blue', 'O', '4']\n",
      "['7720', '7.92', '1.34', '2.44', 'yellow-white', 'F', '3']\n",
      "['2994', '0.0072', '0.28', '13.45', 'Red', 'M', '1']\n",
      "['3270', '150000', '88', '-6.02', 'Red', 'M', '4']\n",
      "['11567', '251000', '36', '-6.245', 'Blue', 'O', '4']\n",
      "['3158', '0.00135', '0.161', '13.98', 'Red', 'M', '1']\n",
      "['34190', '198200', '6.39', '-4.57', 'Blue', 'O', '3']\n",
      "['3134', '0.0004', '0.196', '13.21', 'Red', 'M', '1']\n",
      "['3615', '200000', '1635', '-11.33', 'Red', 'M', '5']\n",
      "['3129', '0.0122', '0.3761', '11.79', 'Red', 'M', '1']\n",
      "['2968', '0.000461', '0.119', '17.45', 'Red', 'M', '0']\n",
      "['9675', '0.00045', '0.0109', '13.98', 'Blue White', 'A', '2']\n",
      "['3542', '0.0009', '0.62', '14.23', 'Red', 'M', '1']\n",
      "['14520', '0.00082', '0.00972', '11.92', 'Blue White', 'B', '2']\n",
      "['5752', '245000', '97', '-6.63', 'Blue', 'O', '4']\n",
      "['17920', '0.00111', '0.0106', '11.66', 'Blue', 'B', '2']\n",
      "['11096', '112000', '12', '-5.91', 'Blue', 'O', '4']\n",
      "['5800', '0.81', '0.9', '5.05', 'yellow-white', 'F', '3']\n",
      "['24345', '142000', '57', '-6.24', 'Blue', 'O', '4']\n",
      "['3490', '270000', '1520', '-9.4', 'Red', 'M', '5']\n",
      "['23440', '537430', '81', '-5.975', 'Blue', 'O', '4']\n",
      "['3614', '145000', '1553', '-7.71', 'Red', 'M', '5']\n",
      "['18000', '200000', '1045', '-8.3', 'Blue', 'O', '5']\n",
      "['1939', '0.000138', '0.103', '20.06', 'Red', 'M', '0']\n",
      "['2989', '0.0087', '0.34', '13.12', 'Red', 'M', '1']\n",
      "['3008', '280000', '25', '-6', 'Red', 'M', '4']\n",
      "['5112', '0.63', '0.876', '4.68', 'Orange-Red', 'K', '3']\n",
      "['22012', '6748', '6.64', '-2.55', 'Blue-white', 'B', '3']\n",
      "['11790', '0.00015', '0.011', '12.59', 'Yellowish White', 'F', '2']\n",
      "['3243', '0.0023', '0.73', '14.75', 'Red', 'M', '1']\n",
      "['8924', '0.00028', '0.00879', '14.87', 'Blue white', 'A', '2']\n",
      "['3218', '0.000452', '0.0987', '17.34', 'Red', 'M', '0']\n",
      "['38234', '272830', '1356', '-9.29', 'Blue', 'O', '5']\n",
      "['3607', '0.022', '0.38', '10.12', 'Red', 'M', '1']\n",
      "['6850', '229000', '1467', '-10.07', 'Red', 'G', '5']\n",
      "['3523', '0.000957', '0.129', '16.35', 'Red', 'M', '0']\n",
      "['30839', '834042', '1194', '-10.63', 'Blue', 'O', '5']\n",
      "['3598', '0.0011', '0.56', '14.26', 'Red', 'M', '1']\n",
      "['3550', '0.004', '0.291', '10.89', 'Red', 'M', '1']\n",
      "['32489', '648430', '1948.5', '-10.84', 'Blue', 'O', '5']\n",
      "['8250', '9.25', '1.93', '-0.98', 'yellow-white', 'F', '3']\n",
      "['9030', '45', '2.63', '1.45', 'Blue-white', 'A', '3']\n",
      "['8945', '38', '2.487', '0.12', 'Blue-White', 'A', '3']\n",
      "['29560', '188000', '6.02', '-4.01', 'Blue-white', 'B', '3']\n",
      "['22350', '12450', '6.36', '-3.67', 'Blue-white', 'B', '3']\n",
      "['4980', '0.357', '1.13', '4.78', 'Yellowish', 'K', '3']\n",
      "['3192', '0.00362', '0.1967', '13.53', 'Red', 'M', '1']\n",
      "['7700', '0.00011', '0.0128', '14.47', 'Yellowish White', 'F', '2']\n",
      "['6757', '1.43', '1.12', '2.41', 'yellow-white', 'F', '3']\n",
      "['3450', '174000', '1284', '-11.28', 'Red', 'M', '5']\n",
      "['30000', '28840', '6.3', '-4.2', 'Blue-white', 'B', '3']\n",
      "['3295', '0.00098', '0.132', '17.13', 'Red', 'M', '0']\n",
      "['13420', '0.00059', '0.00981', '13.67', 'Blue White', 'B', '2']\n",
      "['19860', '0.0011', '0.0131', '11.34', 'Blue', 'B', '2']\n",
      "['13023', '998', '6.21', '-1.38', 'Blue-white', 'A', '3']\n",
      "['39000', '204000', '10.6', '-4.7', 'Blue', 'O', '3']\n",
      "['12010', '0.00078', '0.0092', '12.13', 'Blue White', 'B', '2']\n"
     ]
    }
   ],
   "source": [
    "with open('assignment_ds.csv',newline='') as File:\n",
    "    reader = csv.reader(File)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = pd.read_csv(\"assignment_ds.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>A_M</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spectral_Class</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3453</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.07730</td>\n",
       "      <td>17.08</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12098</td>\n",
       "      <td>689.000000</td>\n",
       "      <td>7.01000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2731</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.08560</td>\n",
       "      <td>18.09</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37800</td>\n",
       "      <td>202900.000000</td>\n",
       "      <td>6.86000</td>\n",
       "      <td>-4.56</td>\n",
       "      <td>Blue</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8570</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.00970</td>\n",
       "      <td>14.20</td>\n",
       "      <td>Blue white</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>13420</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.00981</td>\n",
       "      <td>13.67</td>\n",
       "      <td>Blue White</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>19860</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.01310</td>\n",
       "      <td>11.34</td>\n",
       "      <td>Blue</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>13023</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>6.21000</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>39000</td>\n",
       "      <td>204000.000000</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>Blue</td>\n",
       "      <td>O</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>12010</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.00920</td>\n",
       "      <td>12.13</td>\n",
       "      <td>Blue White</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature              L         R    A_M       Color Spectral_Class  \\\n",
       "0           3453       0.000621   0.07730  17.08         Red              M   \n",
       "1          12098     689.000000   7.01000   0.02  Blue-white              A   \n",
       "2           2731       0.000437   0.08560  18.09         Red              M   \n",
       "3          37800  202900.000000   6.86000  -4.56        Blue              O   \n",
       "4           8570       0.000810   0.00970  14.20  Blue white              A   \n",
       "..           ...            ...       ...    ...         ...            ...   \n",
       "195        13420       0.000590   0.00981  13.67  Blue White              B   \n",
       "196        19860       0.001100   0.01310  11.34        Blue              B   \n",
       "197        13023     998.000000   6.21000  -1.38  Blue-white              A   \n",
       "198        39000  204000.000000  10.60000  -4.70        Blue              O   \n",
       "199        12010       0.000780   0.00920  12.13  Blue White              B   \n",
       "\n",
       "     Type  \n",
       "0       0  \n",
       "1       3  \n",
       "2       0  \n",
       "3       3  \n",
       "4       2  \n",
       "..    ...  \n",
       "195     2  \n",
       "196     2  \n",
       "197     3  \n",
       "198     3  \n",
       "199     2  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_index(limit):\n",
    "    number = 0\n",
    "    index_list = list(range(limit))\n",
    "    random.shuffle(index_list)\n",
    "    return index_list\n",
    "def select_variables(stars,index_list,number_train):\n",
    "    #0:6\n",
    "    #stars.iloc[filas: indices[0->number_rows_for_train] , columnas ]\n",
    "    x_train = stars.iloc[index_list[0:number_train],0:4]\n",
    "    x_test = stars.iloc[index_list[number_train:],0:4]\n",
    "    \n",
    "    y_train = stars.iloc[index_list[:number_train], -1]\n",
    "    y_test =  stars.iloc[index_list[number_train:], -1]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>A_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3749</td>\n",
       "      <td>550000.000000</td>\n",
       "      <td>1648.00000</td>\n",
       "      <td>-8.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>14060</td>\n",
       "      <td>1092.000000</td>\n",
       "      <td>5.74500</td>\n",
       "      <td>-2.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3511</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>17.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>25390</td>\n",
       "      <td>223000.000000</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>-5.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3660</td>\n",
       "      <td>363000.000000</td>\n",
       "      <td>1673.00000</td>\n",
       "      <td>-11.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>3490</td>\n",
       "      <td>270000.000000</td>\n",
       "      <td>1520.00000</td>\n",
       "      <td>-9.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17200</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.01500</td>\n",
       "      <td>12.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23092</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.01040</td>\n",
       "      <td>10.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2637</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.12700</td>\n",
       "      <td>17.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3129</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.37610</td>\n",
       "      <td>11.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12100</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>708.90000</td>\n",
       "      <td>-7.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>8924</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>14.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3600</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>1190.00000</td>\n",
       "      <td>-7.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>8500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>14.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>27739</td>\n",
       "      <td>849420.000000</td>\n",
       "      <td>1252.00000</td>\n",
       "      <td>-7.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>40000</td>\n",
       "      <td>813000.000000</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>-6.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>8945</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>2.48700</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2774</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.11800</td>\n",
       "      <td>17.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>8930</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.00950</td>\n",
       "      <td>13.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>9320</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.91000</td>\n",
       "      <td>1.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15680</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.01140</td>\n",
       "      <td>11.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3750</td>\n",
       "      <td>283000.000000</td>\n",
       "      <td>1260.00000</td>\n",
       "      <td>-7.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>18000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>1045.00000</td>\n",
       "      <td>-8.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>19360</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.00998</td>\n",
       "      <td>11.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2817</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.09110</td>\n",
       "      <td>16.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9383</td>\n",
       "      <td>342940.000000</td>\n",
       "      <td>98.00000</td>\n",
       "      <td>-6.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2890</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.24000</td>\n",
       "      <td>13.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>12912</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.00945</td>\n",
       "      <td>12.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>13340</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.01160</td>\n",
       "      <td>12.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>8250</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>1.93000</td>\n",
       "      <td>-0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>22350</td>\n",
       "      <td>12450.000000</td>\n",
       "      <td>6.36000</td>\n",
       "      <td>-3.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>13023</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>6.21000</td>\n",
       "      <td>-1.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3419</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>17.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3535</td>\n",
       "      <td>195000.000000</td>\n",
       "      <td>1546.00000</td>\n",
       "      <td>-11.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3607</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.38000</td>\n",
       "      <td>10.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>18734</td>\n",
       "      <td>224780.000000</td>\n",
       "      <td>46.00000</td>\n",
       "      <td>-7.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>19860</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.01310</td>\n",
       "      <td>11.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>29560</td>\n",
       "      <td>188000.000000</td>\n",
       "      <td>6.02000</td>\n",
       "      <td>-4.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3531</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.09760</td>\n",
       "      <td>19.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3324</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.47100</td>\n",
       "      <td>12.780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature              L           R     A_M\n",
       "129         3749  550000.000000  1648.00000  -8.050\n",
       "90         14060    1092.000000     5.74500  -2.040\n",
       "67          3511       0.000640     0.10900  17.120\n",
       "42         25390  223000.000000    57.00000  -5.920\n",
       "58          3660  363000.000000  1673.00000 -11.920\n",
       "162         3490  270000.000000  1520.00000  -9.400\n",
       "15         17200       0.000980     0.01500  12.450\n",
       "22         23092       0.001320     0.01040  10.180\n",
       "60          2637       0.000730     0.12700  17.220\n",
       "152         3129       0.012200     0.37610  11.790\n",
       "36         12100  120000.000000   708.90000  -7.840\n",
       "173         8924       0.000280     0.00879  14.870\n",
       "66          3600  240000.000000  1190.00000  -7.890\n",
       "140         8500       0.000500     0.01000  14.500\n",
       "115        27739  849420.000000  1252.00000  -7.590\n",
       "110        40000  813000.000000    14.00000  -6.230\n",
       "185         8945      38.000000     2.48700   0.120\n",
       "38          2774       0.000360     0.11800  17.390\n",
       "135         8930       0.000560     0.00950  13.780\n",
       "50          9320      29.000000     1.91000   1.236\n",
       "34         15680       0.001220     0.01140  11.920\n",
       "132         3750  283000.000000  1260.00000  -7.630\n",
       "165        18000  200000.000000  1045.00000  -8.300\n",
       "63         19360       0.001250     0.00998  11.620\n",
       "103         2817       0.000980     0.09110  16.450\n",
       "13          9383  342940.000000    98.00000  -6.980\n",
       "48          2890       0.003400     0.24000  13.460\n",
       "49         12912       0.000710     0.00945  12.830\n",
       "118        13340       0.001090     0.01160  12.900\n",
       "183         8250       9.250000     1.93000  -0.980\n",
       "187        22350   12450.000000     6.36000  -3.670\n",
       "197        13023     998.000000     6.21000  -1.380\n",
       "11          3419       0.000245     0.12600  17.560\n",
       "37          3535  195000.000000  1546.00000 -11.360\n",
       "176         3607       0.022000     0.38000  10.120\n",
       "112        18734  224780.000000    46.00000  -7.450\n",
       "196        19860       0.001100     0.01310  11.340\n",
       "186        29560  188000.000000     6.02000  -4.010\n",
       "72          3531       0.000930     0.09760  19.940\n",
       "116         3324       0.006500     0.47100  12.780"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list = rand_index(stars.shape[0])\n",
    "\n",
    "x_train, y_train, x_test, y_test = select_variables(stars,index_list, 160)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='selu'))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "\n",
    "#alvarito\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal',activation='relu'))\n",
    "#model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(list_train):\n",
    "    y = []\n",
    "    ls = []\n",
    "    for i in list_train:\n",
    "        ls = [0 for i in range(6)]\n",
    "        ls[i] = 1\n",
    "        y.append(ls)\n",
    "    return pd.DataFrame(y)\n",
    "def IntegerEncode2(target):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(target)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    target = pd.DataFrame(onehot_encoded)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in y_train:\\n    ls = [0 for i in range(6)]\\n    ls[i] = 1\\n    y.append(ls)\\ny = pd.DataFrame(y)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target_training\n",
    "y = []\n",
    "ls = []\n",
    "'''\n",
    "[0,1,2,3,4,5]\n",
    "[\n",
    "[1,0,0,0,0,0]\n",
    "[0,1,0,0,0,0]\n",
    "[0,0,1,0,0,0]\n",
    "[0,0,0,1,0,0]\n",
    "[0,0,0,0,1,0]\n",
    "[0,0,0,0,0,1]\n",
    "]\n",
    "'''\n",
    "y=convert(y_train)\n",
    "target_test=IntegerEncode2(y_test)\n",
    "\n",
    "'''\n",
    "for i in y_train:\n",
    "    ls = [0 for i in range(6)]\n",
    "    ls[i] = 1\n",
    "    y.append(ls)\n",
    "y = pd.DataFrame(y)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.8674 - accuracy: 0.8687 - val_loss: 0.2479 - val_accuracy: 0.8500\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8923 - accuracy: 0.8313 - val_loss: 0.3354 - val_accuracy: 0.9250\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1957 - accuracy: 0.8687 - val_loss: 4.4573 - val_accuracy: 0.9000\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7953 - accuracy: 0.9062 - val_loss: 2.2572 - val_accuracy: 0.7750\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7324 - accuracy: 0.8625 - val_loss: 2.1375 - val_accuracy: 0.9000\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7280 - accuracy: 0.8875 - val_loss: 3.2137 - val_accuracy: 0.9000\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4110 - accuracy: 0.9125 - val_loss: 2.2910 - val_accuracy: 0.8500\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6096 - accuracy: 0.8250 - val_loss: 1.7629 - val_accuracy: 0.9750\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5149 - accuracy: 0.9500 - val_loss: 3.4638 - val_accuracy: 0.9500\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4758 - accuracy: 0.9062 - val_loss: 3.2623 - val_accuracy: 0.9500\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4926 - accuracy: 0.9312 - val_loss: 3.3089 - val_accuracy: 0.9750\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4346 - accuracy: 0.9625 - val_loss: 2.7756 - val_accuracy: 0.9500\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3378 - accuracy: 0.9500 - val_loss: 2.4441 - val_accuracy: 0.9750\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3070 - accuracy: 0.9750 - val_loss: 3.2430 - val_accuracy: 0.9500\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5017 - accuracy: 0.9625 - val_loss: 3.9455 - val_accuracy: 0.9500\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.98 - 0s 15ms/step - loss: 0.5242 - accuracy: 0.9625 - val_loss: 2.7070 - val_accuracy: 0.9750\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9326 - accuracy: 0.9812 - val_loss: 0.1026 - val_accuracy: 0.9750\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1018 - accuracy: 0.9625 - val_loss: 1.1075 - val_accuracy: 0.9750\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4469 - accuracy: 0.9563 - val_loss: 4.4257 - val_accuracy: 0.9750\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6364 - accuracy: 0.9937 - val_loss: 3.0171 - val_accuracy: 0.9750\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3564 - accuracy: 0.9688 - val_loss: 2.6563 - val_accuracy: 0.9750\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7223 - accuracy: 0.9563 - val_loss: 3.6032 - val_accuracy: 0.9750\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1352 - accuracy: 0.9875 - val_loss: 1.0357 - val_accuracy: 0.9750\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2040 - accuracy: 0.9438 - val_loss: 0.1026 - val_accuracy: 0.9500\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2903 - accuracy: 0.9375 - val_loss: 1.9864 - val_accuracy: 0.9750\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7009 - accuracy: 0.9625 - val_loss: 5.3353 - val_accuracy: 0.9750\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.3610 - accuracy: 0.9688 - val_loss: 3.0775 - val_accuracy: 0.9750\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.8512 - accuracy: 0.9625 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.2041 - accuracy: 0.9750 - val_loss: 0.3395 - val_accuracy: 0.9750\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7745 - accuracy: 0.9875 - val_loss: 3.2708 - val_accuracy: 0.9500\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3291 - accuracy: 0.9750 - val_loss: 4.0277 - val_accuracy: 0.9750\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5221 - accuracy: 0.9875 - val_loss: 2.9287 - val_accuracy: 0.9750\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3082 - accuracy: 0.9875 - val_loss: 2.9167 - val_accuracy: 0.9750\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4891 - accuracy: 0.9750 - val_loss: 3.0235 - val_accuracy: 0.9750\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3331 - accuracy: 0.9875 - val_loss: 1.7389 - val_accuracy: 0.9750\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4592 - accuracy: 0.9563 - val_loss: 2.8054 - val_accuracy: 0.9750\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6901 - accuracy: 0.9625 - val_loss: 4.0249 - val_accuracy: 0.9500\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4352 - accuracy: 0.9625 - val_loss: 2.2465 - val_accuracy: 0.9000\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7361 - accuracy: 0.9375 - val_loss: 0.3237 - val_accuracy: 0.9750\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0391 - accuracy: 0.9312 - val_loss: 1.3387 - val_accuracy: 0.9750\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4671 - accuracy: 0.9875 - val_loss: 3.8703 - val_accuracy: 0.9750\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5428 - accuracy: 0.9375 - val_loss: 4.0599 - val_accuracy: 0.9250\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6344 - accuracy: 0.9187 - val_loss: 2.3217 - val_accuracy: 0.9250\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4318 - accuracy: 0.8875 - val_loss: 2.2614 - val_accuracy: 0.9000\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4473 - accuracy: 0.9000 - val_loss: 2.3458 - val_accuracy: 0.9750\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3293 - accuracy: 0.9563 - val_loss: 3.1294 - val_accuracy: 0.9750\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5307 - accuracy: 0.9187 - val_loss: 2.9763 - val_accuracy: 0.9750\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2705 - accuracy: 0.9625 - val_loss: 0.9308 - val_accuracy: 0.9500\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2482 - accuracy: 0.9187 - val_loss: 0.6436 - val_accuracy: 0.9750\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8352 - accuracy: 0.9250 - val_loss: 5.7998 - val_accuracy: 0.9750\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.9050 - accuracy: 0.9500 - val_loss: 2.3526 - val_accuracy: 0.9750\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6727 - accuracy: 0.9688 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.2953 - accuracy: 0.9312 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9777 - accuracy: 0.9375 - val_loss: 5.2179 - val_accuracy: 0.9250\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7789 - accuracy: 0.8750 - val_loss: 2.6403 - val_accuracy: 0.9750\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6728 - accuracy: 0.9625 - val_loss: 0.1028 - val_accuracy: 0.9750\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0460 - accuracy: 0.9688 - val_loss: 1.2495 - val_accuracy: 0.9750\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3966 - accuracy: 0.9750 - val_loss: 4.8991 - val_accuracy: 0.9750\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0891 - accuracy: 0.9688 - val_loss: 1.8933 - val_accuracy: 0.9500\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1609 - accuracy: 0.9500 - val_loss: 0.1344 - val_accuracy: 0.9250\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.7005 - accuracy: 0.9062 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6052 - accuracy: 0.9500 - val_loss: 6.8647 - val_accuracy: 0.9750\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.4360 - accuracy: 0.9000 - val_loss: 4.9161 - val_accuracy: 0.9750\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4218 - accuracy: 0.8813 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4119 - accuracy: 0.9812 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3612 - accuracy: 0.9750 - val_loss: 3.0238 - val_accuracy: 0.9750\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6182 - accuracy: 0.9688 - val_loss: 3.8370 - val_accuracy: 0.9750\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3918 - accuracy: 0.9812 - val_loss: 2.1364 - val_accuracy: 0.9750\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7511 - accuracy: 0.9937 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2188 - accuracy: 0.9750 - val_loss: 0.8530 - val_accuracy: 0.9750\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8662 - accuracy: 0.9812 - val_loss: 3.5456 - val_accuracy: 0.9500\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5032 - accuracy: 0.9688 - val_loss: 2.9531 - val_accuracy: 0.9000\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4971 - accuracy: 0.9375 - val_loss: 2.3964 - val_accuracy: 0.9500\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2607 - accuracy: 0.9500 - val_loss: 4.2990 - val_accuracy: 0.9750\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0935 - accuracy: 0.9312 - val_loss: 1.1259 - val_accuracy: 0.9000\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.8133 - accuracy: 0.9312 - val_loss: 0.1134 - val_accuracy: 0.9500\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5196 - accuracy: 0.8875 - val_loss: 1.7882 - val_accuracy: 0.9500\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3294 - accuracy: 0.8813 - val_loss: 5.3570 - val_accuracy: 0.9000\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.6632 - accuracy: 0.9000 - val_loss: 2.8410 - val_accuracy: 0.9250\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6609 - accuracy: 0.9438 - val_loss: 1.2212 - val_accuracy: 0.9250\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6176 - accuracy: 0.8875 - val_loss: 3.6247 - val_accuracy: 0.9750\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7123 - accuracy: 0.9438 - val_loss: 4.9343 - val_accuracy: 0.9500\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8234 - accuracy: 0.9375 - val_loss: 1.9934 - val_accuracy: 0.9500\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7171 - accuracy: 0.9563 - val_loss: 1.5081 - val_accuracy: 0.9750\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4840 - accuracy: 0.9625 - val_loss: 2.5492 - val_accuracy: 0.9750\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3649 - accuracy: 0.9563 - val_loss: 2.1772 - val_accuracy: 0.9750\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4146 - accuracy: 0.9187 - val_loss: 1.7361 - val_accuracy: 0.9750\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5130 - accuracy: 0.9500 - val_loss: 1.1898 - val_accuracy: 0.9500\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.5777 - accuracy: 0.9563 - val_loss: 3.1571 - val_accuracy: 0.9750\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7379 - accuracy: 0.9375 - val_loss: 3.6077 - val_accuracy: 0.9500\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4609 - accuracy: 0.9062 - val_loss: 1.1449 - val_accuracy: 0.9000\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7854 - accuracy: 0.8938 - val_loss: 1.3209 - val_accuracy: 0.9500\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6333 - accuracy: 0.8500 - val_loss: 3.6358 - val_accuracy: 0.9750\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4562 - accuracy: 0.9187 - val_loss: 4.1865 - val_accuracy: 0.9750\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5409 - accuracy: 0.9563 - val_loss: 1.9607 - val_accuracy: 0.9750\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0849 - accuracy: 0.9812 - val_loss: 0.0971 - val_accuracy: 0.9750\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0881 - accuracy: 0.9125 - val_loss: 2.0349 - val_accuracy: 0.9750\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3605 - accuracy: 0.9937 - val_loss: 4.6604 - val_accuracy: 0.9750\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7991 - accuracy: 0.9563 - val_loss: 2.8232 - val_accuracy: 0.9750\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2995 - accuracy: 0.9875 - val_loss: 0.3314 - val_accuracy: 0.9750\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1702 - accuracy: 0.9563 - val_loss: 0.2346 - val_accuracy: 0.9750\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7219 - accuracy: 0.9500 - val_loss: 3.1191 - val_accuracy: 0.9750\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.9276 - accuracy: 0.9500 - val_loss: 3.9304 - val_accuracy: 0.9500\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.5779 - accuracy: 0.8500 - val_loss: 0.1468 - val_accuracy: 0.9250\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.7523 - accuracy: 0.7937 - val_loss: 0.7697 - val_accuracy: 0.9500\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6051 - accuracy: 0.8875 - val_loss: 4.4490 - val_accuracy: 0.9500\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.6232 - accuracy: 0.8813 - val_loss: 0.8305 - val_accuracy: 0.9500\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.3833 - accuracy: 0.9187 - val_loss: 0.1168 - val_accuracy: 0.9750\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 5.7568 - accuracy: 0.8813 - val_loss: 0.1170 - val_accuracy: 0.9500\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.4178 - accuracy: 0.9375 - val_loss: 6.0543 - val_accuracy: 0.9500\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.2806 - accuracy: 0.8875 - val_loss: 4.7089 - val_accuracy: 0.9500\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.4499 - accuracy: 0.9625 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.1630 - accuracy: 0.9500 - val_loss: 0.0979 - val_accuracy: 0.9750\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9532 - accuracy: 0.9500 - val_loss: 5.0924 - val_accuracy: 0.9750\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.7368 - accuracy: 0.9187 - val_loss: 4.4686 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.8878 - accuracy: 0.9625 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.3654 - accuracy: 0.9438 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0727 - accuracy: 0.9563 - val_loss: 3.5859 - val_accuracy: 0.9750\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4098 - accuracy: 0.9563 - val_loss: 5.8473 - val_accuracy: 0.9750\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3183 - accuracy: 0.9750 - val_loss: 2.7255 - val_accuracy: 0.9750\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2961 - accuracy: 0.9750 - val_loss: 2.0993 - val_accuracy: 0.9500\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4668 - accuracy: 0.9625 - val_loss: 3.0952 - val_accuracy: 0.9500\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3527 - accuracy: 0.9688 - val_loss: 2.6827 - val_accuracy: 0.9750\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4583 - accuracy: 0.9688 - val_loss: 2.3673 - val_accuracy: 0.9750\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3065 - accuracy: 0.9875 - val_loss: 5.3426 - val_accuracy: 0.9750\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8338 - accuracy: 0.9625 - val_loss: 0.7611 - val_accuracy: 0.9500\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8273 - accuracy: 0.9500 - val_loss: 0.1292 - val_accuracy: 0.9250\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.9139 - accuracy: 0.9312 - val_loss: 0.0753 - val_accuracy: 0.9750\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0224 - accuracy: 0.9625 - val_loss: 6.1182 - val_accuracy: 0.9250\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 5.1258 - accuracy: 0.9125 - val_loss: 6.1235 - val_accuracy: 0.7500\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5245 - accuracy: 0.8313 - val_loss: 0.2046 - val_accuracy: 0.8500\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 5.6926 - accuracy: 0.8625 - val_loss: 0.0944 - val_accuracy: 0.9500\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4.2601 - accuracy: 0.9563 - val_loss: 0.1055 - val_accuracy: 0.9500\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6098 - accuracy: 0.9312 - val_loss: 5.9689 - val_accuracy: 0.9000\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.4284 - accuracy: 0.8687 - val_loss: 1.2386 - val_accuracy: 0.9000\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3334 - accuracy: 0.8562 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.8854 - accuracy: 0.9625 - val_loss: 1.1606 - val_accuracy: 0.9750\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5528 - accuracy: 0.9688 - val_loss: 4.7624 - val_accuracy: 0.9750\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9969 - accuracy: 0.9500 - val_loss: 2.9284 - val_accuracy: 0.9750\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6254 - accuracy: 0.9375 - val_loss: 0.0810 - val_accuracy: 0.9750\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.4747 - accuracy: 0.8750 - val_loss: 0.0982 - val_accuracy: 0.9750\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0682 - accuracy: 0.9187 - val_loss: 2.8802 - val_accuracy: 0.9750\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3207 - accuracy: 0.9375 - val_loss: 5.4833 - val_accuracy: 0.9750\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2611 - accuracy: 0.9312 - val_loss: 2.9932 - val_accuracy: 0.9750\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2905 - accuracy: 0.9875 - val_loss: 2.4321 - val_accuracy: 0.9750\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3693 - accuracy: 0.9625 - val_loss: 1.6893 - val_accuracy: 0.9750\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6507 - accuracy: 0.9500 - val_loss: 1.3701 - val_accuracy: 0.9750\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5138 - accuracy: 0.9563 - val_loss: 3.9930 - val_accuracy: 0.9750\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5108 - accuracy: 0.9563 - val_loss: 4.0414 - val_accuracy: 0.9750\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5189 - accuracy: 0.9750 - val_loss: 2.7856 - val_accuracy: 0.9750\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4958 - accuracy: 0.9875 - val_loss: 0.2524 - val_accuracy: 0.9750\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1662 - accuracy: 0.9812 - val_loss: 0.6160 - val_accuracy: 0.9750\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8590 - accuracy: 0.9563 - val_loss: 4.1239 - val_accuracy: 0.9500\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6959 - accuracy: 0.9500 - val_loss: 2.6123 - val_accuracy: 0.9750\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1170 - accuracy: 0.9250 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2108 - accuracy: 0.9625 - val_loss: 2.5366 - val_accuracy: 0.9750\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3926 - accuracy: 0.9563 - val_loss: 6.4680 - val_accuracy: 0.9750\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.3417 - accuracy: 0.8938 - val_loss: 2.0559 - val_accuracy: 0.9250\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5846 - accuracy: 0.9062 - val_loss: 0.3892 - val_accuracy: 0.9250\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.1646 - accuracy: 0.8625 - val_loss: 1.3247 - val_accuracy: 0.9500\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5023 - accuracy: 0.8875 - val_loss: 5.0393 - val_accuracy: 0.9250\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0263 - accuracy: 0.8562 - val_loss: 3.2276 - val_accuracy: 0.9250\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5317 - accuracy: 0.8750 - val_loss: 0.0901 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5185 - accuracy: 0.9438 - val_loss: 0.8544 - val_accuracy: 0.9750\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9075 - accuracy: 0.9563 - val_loss: 5.5572 - val_accuracy: 0.9750\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5659 - accuracy: 0.8813 - val_loss: 1.8138 - val_accuracy: 0.9750\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4643 - accuracy: 0.9312 - val_loss: 2.2844 - val_accuracy: 0.9250\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2828 - accuracy: 0.9750 - val_loss: 3.8162 - val_accuracy: 0.9250\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6241 - accuracy: 0.9438 - val_loss: 2.9994 - val_accuracy: 0.9750\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2084 - accuracy: 0.9688 - val_loss: 1.2703 - val_accuracy: 0.9750\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7854 - accuracy: 0.9563 - val_loss: 1.9116 - val_accuracy: 0.9500\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3562 - accuracy: 0.9312 - val_loss: 3.9206 - val_accuracy: 0.9500\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7404 - accuracy: 0.9750 - val_loss: 3.0454 - val_accuracy: 0.9750\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8517 - accuracy: 0.9438 - val_loss: 0.0821 - val_accuracy: 0.9750\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.3203 - accuracy: 0.9625 - val_loss: 0.0680 - val_accuracy: 0.9750\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9464 - accuracy: 0.9750 - val_loss: 2.7471 - val_accuracy: 0.9250\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4093 - accuracy: 0.9500 - val_loss: 3.7505 - val_accuracy: 0.9500\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4804 - accuracy: 0.9438 - val_loss: 2.6458 - val_accuracy: 0.9750\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3647 - accuracy: 0.9625 - val_loss: 2.0897 - val_accuracy: 0.9750\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3494 - accuracy: 0.9937 - val_loss: 2.7884 - val_accuracy: 0.9750\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3912 - accuracy: 0.9875 - val_loss: 2.9545 - val_accuracy: 0.9750\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3408 - accuracy: 0.9812 - val_loss: 3.5345 - val_accuracy: 0.9500\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4268 - accuracy: 0.9500 - val_loss: 2.6649 - val_accuracy: 0.9750\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9223 - accuracy: 0.9312 - val_loss: 1.5129 - val_accuracy: 0.9750\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5074 - accuracy: 0.9812 - val_loss: 6.6558 - val_accuracy: 0.9750\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.0319 - accuracy: 0.9312 - val_loss: 2.4390 - val_accuracy: 0.9750\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4622 - accuracy: 0.9375 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.4509 - accuracy: 0.9062 - val_loss: 0.8717 - val_accuracy: 0.9750\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6952 - accuracy: 0.8875 - val_loss: 6.2980 - val_accuracy: 0.9750\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.4783 - accuracy: 0.8000 - val_loss: 2.3388 - val_accuracy: 0.9750\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8280 - accuracy: 0.8250 - val_loss: 0.1197 - val_accuracy: 0.9750\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.3769 - accuracy: 0.8438 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9412 - accuracy: 0.8938 - val_loss: 3.0439 - val_accuracy: 0.9750\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2077 - accuracy: 0.9125 - val_loss: 4.8956 - val_accuracy: 0.8750\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7927 - accuracy: 0.9187 - val_loss: 0.4426 - val_accuracy: 0.8250\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3976 - accuracy: 0.8625 - val_loss: 0.1100 - val_accuracy: 0.9500\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1503 - accuracy: 0.9688 - val_loss: 2.0816 - val_accuracy: 0.9500\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4445 - accuracy: 0.9000 - val_loss: 7.6048 - val_accuracy: 0.9500\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 4.7797 - accuracy: 0.9125 - val_loss: 4.2079 - val_accuracy: 0.9750\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6809 - accuracy: 0.9625 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.1911 - accuracy: 0.9812 - val_loss: 0.0818 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.8960 - accuracy: 0.9250 - val_loss: 1.8066 - val_accuracy: 0.9750\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4281 - accuracy: 0.9875 - val_loss: 5.3964 - val_accuracy: 0.9500\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1468 - accuracy: 0.9312 - val_loss: 0.5726 - val_accuracy: 0.9500\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.6787 - accuracy: 0.9125 - val_loss: 0.1390 - val_accuracy: 0.9000\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 7.2362 - accuracy: 0.8188 - val_loss: 0.0807 - val_accuracy: 0.9750\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4464 - accuracy: 0.9375 - val_loss: 5.9700 - val_accuracy: 0.9750\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.6420 - accuracy: 0.9187 - val_loss: 5.4469 - val_accuracy: 0.8500\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7972 - accuracy: 0.8875 - val_loss: 0.1728 - val_accuracy: 0.9500\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.2780 - accuracy: 0.8125 - val_loss: 0.0827 - val_accuracy: 0.9750\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4407 - accuracy: 0.8687 - val_loss: 4.3829 - val_accuracy: 0.9250\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2609 - accuracy: 0.8813 - val_loss: 3.3104 - val_accuracy: 0.9000\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6037 - accuracy: 0.8562 - val_loss: 0.7744 - val_accuracy: 0.9750\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9362 - accuracy: 0.8375 - val_loss: 2.0648 - val_accuracy: 0.9250\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3851 - accuracy: 0.8562 - val_loss: 4.4089 - val_accuracy: 0.9500\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5791 - accuracy: 0.8750 - val_loss: 4.5907 - val_accuracy: 0.9500\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5433 - accuracy: 0.8375 - val_loss: 1.3330 - val_accuracy: 0.9500\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9091 - accuracy: 0.8375 - val_loss: 2.7795 - val_accuracy: 0.9250\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7087 - accuracy: 0.8125 - val_loss: 4.8076 - val_accuracy: 0.9500\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9242 - accuracy: 0.9187 - val_loss: 2.9465 - val_accuracy: 0.8250\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6739 - accuracy: 0.8375 - val_loss: 0.7618 - val_accuracy: 0.8750\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9921 - accuracy: 0.8313 - val_loss: 2.1374 - val_accuracy: 0.9000\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3545 - accuracy: 0.8375 - val_loss: 4.3225 - val_accuracy: 0.9750\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2558 - accuracy: 0.9563 - val_loss: 4.8204 - val_accuracy: 0.9750\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8205 - accuracy: 0.9812 - val_loss: 2.9022 - val_accuracy: 0.9750\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4526 - accuracy: 0.9812 - val_loss: 2.9612 - val_accuracy: 0.9750\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7347 - accuracy: 0.9688 - val_loss: 2.4603 - val_accuracy: 0.9750\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1038 - accuracy: 0.9875 - val_loss: 5.7543 - val_accuracy: 0.9500\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.0687 - accuracy: 0.9438 - val_loss: 1.3094 - val_accuracy: 0.9750\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7278 - accuracy: 0.9563 - val_loss: 0.0861 - val_accuracy: 0.9750\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0654 - accuracy: 0.9688 - val_loss: 3.2007 - val_accuracy: 0.9500\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0991 - accuracy: 0.9500 - val_loss: 4.5625 - val_accuracy: 0.9500\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3292 - accuracy: 0.9500 - val_loss: 1.7824 - val_accuracy: 0.9750\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8224 - accuracy: 0.9812 - val_loss: 0.8606 - val_accuracy: 0.9500\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7907 - accuracy: 0.9375 - val_loss: 2.9088 - val_accuracy: 0.9750\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8177 - accuracy: 0.9812 - val_loss: 5.0494 - val_accuracy: 0.9750\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8039 - accuracy: 0.9812 - val_loss: 1.4017 - val_accuracy: 0.9500\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7529 - accuracy: 0.9563 - val_loss: 1.0571 - val_accuracy: 0.9750\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3477 - accuracy: 0.9875 - val_loss: 3.6165 - val_accuracy: 0.9750\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8968 - accuracy: 0.9688 - val_loss: 4.2585 - val_accuracy: 0.9750\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5717 - accuracy: 0.9812 - val_loss: 0.0828 - val_accuracy: 0.9750\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1181 - accuracy: 0.9250 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3289 - accuracy: 0.9500 - val_loss: 1.5763 - val_accuracy: 0.9750\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3052 - accuracy: 0.9563 - val_loss: 5.0032 - val_accuracy: 0.9750\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0598 - accuracy: 0.9438 - val_loss: 1.7944 - val_accuracy: 0.9250\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3661 - accuracy: 0.9312 - val_loss: 0.1383 - val_accuracy: 0.9250\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6121 - accuracy: 0.9250 - val_loss: 3.6999 - val_accuracy: 0.9250\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2648 - accuracy: 0.9375 - val_loss: 3.0585 - val_accuracy: 0.9500\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5676 - accuracy: 0.9438 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.0749 - accuracy: 0.9563 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.1444 - accuracy: 0.9563 - val_loss: 2.9441 - val_accuracy: 0.9750\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7833 - accuracy: 0.9688 - val_loss: 4.7873 - val_accuracy: 0.9750\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9065 - accuracy: 0.9625 - val_loss: 2.9271 - val_accuracy: 0.9750\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3737 - accuracy: 0.9750 - val_loss: 1.7276 - val_accuracy: 0.9750\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4577 - accuracy: 0.9750 - val_loss: 1.0386 - val_accuracy: 0.9750\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6944 - accuracy: 0.9750 - val_loss: 2.5164 - val_accuracy: 0.9750\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1206 - accuracy: 0.9812 - val_loss: 5.6844 - val_accuracy: 0.9750\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.2459 - accuracy: 0.9625 - val_loss: 0.9875 - val_accuracy: 0.9500\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.5448 - accuracy: 0.9000 - val_loss: 0.0959 - val_accuracy: 0.9750\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.9258 - accuracy: 0.9125 - val_loss: 0.0623 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9139 - accuracy: 0.9563 - val_loss: 4.0437 - val_accuracy: 0.9750\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.2077 - accuracy: 0.9625 - val_loss: 3.2909 - val_accuracy: 0.9500\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2948 - accuracy: 0.9625 - val_loss: 1.4631 - val_accuracy: 0.8250\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6173 - accuracy: 0.8938 - val_loss: 3.6959 - val_accuracy: 0.9250\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8135 - accuracy: 0.9688 - val_loss: 3.4112 - val_accuracy: 0.9500\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3606 - accuracy: 0.9812 - val_loss: 0.8300 - val_accuracy: 0.9750\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7612 - accuracy: 0.9688 - val_loss: 2.2441 - val_accuracy: 0.9750\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3063 - accuracy: 0.9312 - val_loss: 4.1152 - val_accuracy: 0.9500\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5475 - accuracy: 0.9312 - val_loss: 3.8952 - val_accuracy: 0.9250\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4515 - accuracy: 0.9062 - val_loss: 2.1117 - val_accuracy: 0.9250\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7028 - accuracy: 0.9062 - val_loss: 0.0822 - val_accuracy: 0.9750\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.7426 - accuracy: 0.8813 - val_loss: 1.0570 - val_accuracy: 0.9750\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3309 - accuracy: 0.9375 - val_loss: 6.2121 - val_accuracy: 0.9750\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.0627 - accuracy: 0.9500 - val_loss: 1.7729 - val_accuracy: 0.9750\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.6679 - accuracy: 0.9875 - val_loss: 0.1226 - val_accuracy: 0.9250\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 4.5652 - accuracy: 0.9000 - val_loss: 0.0669 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3573 - accuracy: 0.9312 - val_loss: 5.8140 - val_accuracy: 0.9750\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.0654 - accuracy: 0.9312 - val_loss: 1.5041 - val_accuracy: 0.9750\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.4791 - accuracy: 0.9563 - val_loss: 0.0800 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.2433 - accuracy: 0.9500 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3756 - accuracy: 0.9625 - val_loss: 6.3815 - val_accuracy: 0.9750\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.8974 - accuracy: 0.9812 - val_loss: 3.5834 - val_accuracy: 0.9750\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1037 - accuracy: 0.9937 - val_loss: 1.0725 - val_accuracy: 0.9750\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9741 - accuracy: 0.9688 - val_loss: 1.2063 - val_accuracy: 0.9750\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6367 - accuracy: 0.9875 - val_loss: 6.4652 - val_accuracy: 0.9750\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.8616 - accuracy: 0.9563 - val_loss: 2.3708 - val_accuracy: 0.8750\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2425 - accuracy: 0.9375 - val_loss: 0.1418 - val_accuracy: 0.9250\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.8061 - accuracy: 0.8813 - val_loss: 0.0880 - val_accuracy: 0.9500\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1433 - accuracy: 0.9125 - val_loss: 3.1243 - val_accuracy: 0.8500\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2888 - accuracy: 0.8875 - val_loss: 5.8321 - val_accuracy: 0.9500\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4579 - accuracy: 0.8875 - val_loss: 1.6291 - val_accuracy: 0.9500\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9551 - accuracy: 0.9250 - val_loss: 0.5069 - val_accuracy: 0.9750\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8332 - accuracy: 0.9750 - val_loss: 3.0026 - val_accuracy: 0.9750\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3004 - accuracy: 0.9688 - val_loss: 4.1414 - val_accuracy: 0.9750\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7506 - accuracy: 0.9812 - val_loss: 5.1817 - val_accuracy: 0.9750\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8171 - accuracy: 0.9875 - val_loss: 1.4096 - val_accuracy: 0.9500\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7353 - accuracy: 0.9625 - val_loss: 1.1127 - val_accuracy: 0.9750\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5373 - accuracy: 0.9937 - val_loss: 3.9901 - val_accuracy: 0.9750\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7930 - accuracy: 0.9875 - val_loss: 3.1193 - val_accuracy: 0.9750\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2660 - accuracy: 0.9688 - val_loss: 1.1047 - val_accuracy: 0.9750\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7431 - accuracy: 0.9812 - val_loss: 1.5246 - val_accuracy: 0.9750\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2124 - accuracy: 0.9937 - val_loss: 4.5613 - val_accuracy: 0.9750\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6238 - accuracy: 0.9563 - val_loss: 3.7124 - val_accuracy: 0.9250\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4364 - accuracy: 0.9563 - val_loss: 0.1119 - val_accuracy: 0.9500\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2223 - accuracy: 0.9062 - val_loss: 0.1009 - val_accuracy: 0.9500\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0565 - accuracy: 0.9500 - val_loss: 3.3487 - val_accuracy: 0.9000\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5455 - accuracy: 0.9375 - val_loss: 4.0830 - val_accuracy: 0.9500\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5515 - accuracy: 0.9062 - val_loss: 2.4941 - val_accuracy: 0.9750\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7120 - accuracy: 0.9625 - val_loss: 0.6461 - val_accuracy: 0.9750\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7836 - accuracy: 0.9688 - val_loss: 2.6859 - val_accuracy: 0.9500\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7159 - accuracy: 0.9000 - val_loss: 3.9585 - val_accuracy: 0.9500\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4881 - accuracy: 0.9312 - val_loss: 0.4398 - val_accuracy: 0.9750\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0088 - accuracy: 0.9625 - val_loss: 0.4034 - val_accuracy: 0.9500\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8846 - accuracy: 0.9312 - val_loss: 3.2332 - val_accuracy: 0.9750\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3007 - accuracy: 0.9625 - val_loss: 4.6105 - val_accuracy: 0.9250\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1950 - accuracy: 0.9375 - val_loss: 2.8061 - val_accuracy: 0.9500\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2489 - accuracy: 0.9750 - val_loss: 1.0739 - val_accuracy: 0.9500\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6758 - accuracy: 0.9563 - val_loss: 2.2461 - val_accuracy: 0.9750\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2407 - accuracy: 0.9937 - val_loss: 4.5538 - val_accuracy: 0.9750\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0828 - accuracy: 0.9563 - val_loss: 3.5219 - val_accuracy: 0.9000\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3165 - accuracy: 0.8687 - val_loss: 1.9868 - val_accuracy: 0.9000\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4335 - accuracy: 0.8562 - val_loss: 3.6177 - val_accuracy: 0.9500\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4298 - accuracy: 0.9062 - val_loss: 4.5387 - val_accuracy: 0.9750\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7277 - accuracy: 0.9375 - val_loss: 3.4084 - val_accuracy: 0.9500\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3756 - accuracy: 0.9375 - val_loss: 0.7761 - val_accuracy: 0.9750\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0633 - accuracy: 0.9500 - val_loss: 0.9932 - val_accuracy: 0.9750\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5433 - accuracy: 0.9812 - val_loss: 4.7443 - val_accuracy: 0.9500\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1756 - accuracy: 0.9438 - val_loss: 1.5394 - val_accuracy: 0.9750\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4707 - accuracy: 0.9500 - val_loss: 0.0891 - val_accuracy: 0.9500\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.5306 - accuracy: 0.9563 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4133 - accuracy: 0.9375 - val_loss: 6.4308 - val_accuracy: 0.9500\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.2178 - accuracy: 0.8750 - val_loss: 1.5164 - val_accuracy: 0.9500\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5887 - accuracy: 0.9062 - val_loss: 1.2942 - val_accuracy: 0.9750\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6241 - accuracy: 0.9375 - val_loss: 4.1237 - val_accuracy: 0.9750\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7163 - accuracy: 0.9500 - val_loss: 4.5930 - val_accuracy: 0.9750\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4889 - accuracy: 0.9250 - val_loss: 0.7102 - val_accuracy: 0.9750\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2936 - accuracy: 0.9312 - val_loss: 0.1033 - val_accuracy: 0.9500\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3401 - accuracy: 0.9125 - val_loss: 2.3132 - val_accuracy: 0.9750\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2281 - accuracy: 0.9375 - val_loss: 5.4309 - val_accuracy: 0.9750\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2892 - accuracy: 0.8938 - val_loss: 2.7890 - val_accuracy: 0.9750\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4966 - accuracy: 0.9125 - val_loss: 2.5912 - val_accuracy: 0.9750\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4820 - accuracy: 0.9688 - val_loss: 3.5358 - val_accuracy: 0.9250\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1663 - accuracy: 0.9750 - val_loss: 1.2488 - val_accuracy: 0.9750\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8434 - accuracy: 0.9688 - val_loss: 1.6446 - val_accuracy: 0.9500\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4366 - accuracy: 0.9625 - val_loss: 4.2853 - val_accuracy: 0.9500\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6451 - accuracy: 0.9688 - val_loss: 3.1210 - val_accuracy: 0.9750\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6793 - accuracy: 0.9812 - val_loss: 0.1005 - val_accuracy: 0.9500\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.6642 - accuracy: 0.9250 - val_loss: 0.0619 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1715 - accuracy: 0.9688 - val_loss: 3.9322 - val_accuracy: 0.9750\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3477 - accuracy: 0.9625 - val_loss: 2.1143 - val_accuracy: 0.9750\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3456 - accuracy: 0.9875 - val_loss: 1.9651 - val_accuracy: 0.9750\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3772 - accuracy: 0.9937 - val_loss: 3.2347 - val_accuracy: 0.9500\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4025 - accuracy: 0.9875 - val_loss: 3.0395 - val_accuracy: 0.9250\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4786 - accuracy: 0.9312 - val_loss: 2.5633 - val_accuracy: 0.9250\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5449 - accuracy: 0.9375 - val_loss: 2.1023 - val_accuracy: 0.9250\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4216 - accuracy: 0.9000 - val_loss: 3.5389 - val_accuracy: 0.9250\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5176 - accuracy: 0.8687 - val_loss: 3.9315 - val_accuracy: 0.9000\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6530 - accuracy: 0.8500 - val_loss: 2.9137 - val_accuracy: 0.9500\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4772 - accuracy: 0.9000 - val_loss: 2.7669 - val_accuracy: 0.9000\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4567 - accuracy: 0.8625 - val_loss: 3.7145 - val_accuracy: 0.9500\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5724 - accuracy: 0.8938 - val_loss: 2.6609 - val_accuracy: 0.9250\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4796 - accuracy: 0.8875 - val_loss: 1.5641 - val_accuracy: 0.9750\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1648 - accuracy: 0.9937 - val_loss: 4.9512 - val_accuracy: 0.9750\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6632 - accuracy: 0.9688 - val_loss: 1.9685 - val_accuracy: 0.9750\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2107 - accuracy: 0.9875 - val_loss: 0.0742 - val_accuracy: 0.9750\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7911 - accuracy: 0.9187 - val_loss: 5.8203 - val_accuracy: 0.9500\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5607 - accuracy: 0.8875 - val_loss: 1.2161 - val_accuracy: 0.9750\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5409 - accuracy: 0.8875 - val_loss: 0.1313 - val_accuracy: 0.9250\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.5262 - accuracy: 0.9187 - val_loss: 0.1224 - val_accuracy: 0.9250\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.8699 - accuracy: 0.8562 - val_loss: 5.4928 - val_accuracy: 0.9250\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.5002 - accuracy: 0.9000 - val_loss: 2.5942 - val_accuracy: 0.9500\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4436 - accuracy: 0.8750 - val_loss: 0.0895 - val_accuracy: 0.9750\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 4.5422 - accuracy: 0.8813 - val_loss: 0.0984 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.6589 - accuracy: 0.9187 - val_loss: 2.1860 - val_accuracy: 0.9750\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0925 - accuracy: 0.9125 - val_loss: 6.0181 - val_accuracy: 0.8750\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.8635 - accuracy: 0.8938 - val_loss: 1.8638 - val_accuracy: 0.8250\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1020 - accuracy: 0.8125 - val_loss: 0.5447 - val_accuracy: 0.9000\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9624 - accuracy: 0.8250 - val_loss: 2.9123 - val_accuracy: 0.9000\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6015 - accuracy: 0.8750 - val_loss: 2.6574 - val_accuracy: 0.9500\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.3970 - accuracy: 0.8562 - val_loss: 0.1183 - val_accuracy: 0.9500\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.8417 - accuracy: 0.8125 - val_loss: 3.9951 - val_accuracy: 0.9500\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8582 - accuracy: 0.8562 - val_loss: 3.8582 - val_accuracy: 0.9250\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7981 - accuracy: 0.8875 - val_loss: 0.2527 - val_accuracy: 0.8500\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.6733 - accuracy: 0.8750 - val_loss: 0.1614 - val_accuracy: 0.9000\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2320 - accuracy: 0.8562 - val_loss: 2.2769 - val_accuracy: 0.8250\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4529 - accuracy: 0.9062 - val_loss: 7.4686 - val_accuracy: 0.9250\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.9333 - accuracy: 0.8750 - val_loss: 2.3948 - val_accuracy: 0.9750\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.2180 - accuracy: 0.9438 - val_loss: 0.0803 - val_accuracy: 0.9750\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 5.0223 - accuracy: 0.9000 - val_loss: 0.0619 - val_accuracy: 0.9750\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6191 - accuracy: 0.8813 - val_loss: 7.6736 - val_accuracy: 0.9750\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.7910 - accuracy: 0.9563 - val_loss: 1.3016 - val_accuracy: 0.9750\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.3434 - accuracy: 0.9438 - val_loss: 0.1214 - val_accuracy: 0.9750\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7381 - accuracy: 0.9563 - val_loss: 1.6748 - val_accuracy: 0.9750\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.1757 - accuracy: 0.9438 - val_loss: 3.1558 - val_accuracy: 0.9500\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5326 - accuracy: 0.9375 - val_loss: 0.0834 - val_accuracy: 0.9750\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.9519 - accuracy: 0.9125 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.2572 - accuracy: 0.9187 - val_loss: 7.6941 - val_accuracy: 0.9750\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 7.2535 - accuracy: 0.9125 - val_loss: 6.7041 - val_accuracy: 0.8750\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.1111 - accuracy: 0.8188 - val_loss: 0.3956 - val_accuracy: 0.8500\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 4.4863 - accuracy: 0.8125 - val_loss: 0.0966 - val_accuracy: 0.9500\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 15ms/step - loss: 2.7619 - accuracy: 0.9187 - val_loss: 5.1861 - val_accuracy: 0.9500\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.8784 - accuracy: 0.9000 - val_loss: 7.1080 - val_accuracy: 0.8250\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.9671 - accuracy: 0.8875 - val_loss: 0.6181 - val_accuracy: 0.9000\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 5.4708 - accuracy: 0.8562 - val_loss: 0.1087 - val_accuracy: 0.9750\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.4924 - accuracy: 0.9125 - val_loss: 5.0804 - val_accuracy: 0.7000\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.9030 - accuracy: 0.8687 - val_loss: 7.9932 - val_accuracy: 0.9750\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.4791 - accuracy: 0.9250 - val_loss: 1.4497 - val_accuracy: 0.9750\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6461 - accuracy: 0.9250 - val_loss: 0.9068 - val_accuracy: 0.9500\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8011 - accuracy: 0.9750 - val_loss: 3.5678 - val_accuracy: 0.9750\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3869 - accuracy: 0.9688 - val_loss: 4.2679 - val_accuracy: 0.9750\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5212 - accuracy: 0.9812 - val_loss: 1.9499 - val_accuracy: 0.9500\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6873 - accuracy: 0.9500 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3431 - accuracy: 0.9750 - val_loss: 0.6596 - val_accuracy: 0.9750\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8684 - accuracy: 0.9625 - val_loss: 5.2903 - val_accuracy: 0.9500\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.4347 - accuracy: 0.9312 - val_loss: 2.7688 - val_accuracy: 0.9750\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6058 - accuracy: 0.9438 - val_loss: 3.1416 - val_accuracy: 0.9750\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.4076 - accuracy: 0.9438 - val_loss: 3.9137 - val_accuracy: 0.9500\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4868 - accuracy: 0.9438 - val_loss: 0.0952 - val_accuracy: 0.9500\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.9679 - accuracy: 0.9688 - val_loss: 0.4593 - val_accuracy: 0.9500\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2700 - accuracy: 0.9563 - val_loss: 5.1482 - val_accuracy: 0.9750\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7628 - accuracy: 0.9875 - val_loss: 2.2282 - val_accuracy: 0.9500\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5012 - accuracy: 0.9563 - val_loss: 1.0886 - val_accuracy: 0.9750\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7665 - accuracy: 0.9750 - val_loss: 2.8849 - val_accuracy: 0.9750\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7239 - accuracy: 0.9438 - val_loss: 3.2855 - val_accuracy: 0.9750\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2195 - accuracy: 0.9500 - val_loss: 1.5629 - val_accuracy: 0.9500\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9564 - accuracy: 0.9062 - val_loss: 2.4632 - val_accuracy: 0.9750\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3794 - accuracy: 0.9812 - val_loss: 5.2898 - val_accuracy: 0.8500\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0334 - accuracy: 0.9312 - val_loss: 0.0991 - val_accuracy: 0.9750\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.0412 - accuracy: 0.9125 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4273 - accuracy: 0.9625 - val_loss: 3.4250 - val_accuracy: 0.9500\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9851 - accuracy: 0.9375 - val_loss: 4.0564 - val_accuracy: 0.9250\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6622 - accuracy: 0.9062 - val_loss: 1.6655 - val_accuracy: 0.9250\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5411 - accuracy: 0.9250 - val_loss: 2.9401 - val_accuracy: 0.9250\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7678 - accuracy: 0.9438 - val_loss: 5.9288 - val_accuracy: 0.9500\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.7834 - accuracy: 0.9563 - val_loss: 1.7707 - val_accuracy: 0.9500\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5709 - accuracy: 0.9688 - val_loss: 2.9741 - val_accuracy: 0.9250\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3830 - accuracy: 0.9438 - val_loss: 3.7346 - val_accuracy: 0.9250\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5944 - accuracy: 0.9062 - val_loss: 1.1969 - val_accuracy: 0.9000\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6791 - accuracy: 0.8687 - val_loss: 3.4435 - val_accuracy: 0.9500\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.4023 - accuracy: 0.9125 - val_loss: 4.1963 - val_accuracy: 0.9750\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6700 - accuracy: 0.9438 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1254 - accuracy: 0.9625 - val_loss: 1.1639 - val_accuracy: 0.9750\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4355 - accuracy: 0.9625 - val_loss: 3.0848 - val_accuracy: 0.9750\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4826 - accuracy: 0.9812 - val_loss: 3.3206 - val_accuracy: 0.9750\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4315 - accuracy: 0.9500 - val_loss: 2.6633 - val_accuracy: 0.9500\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3092 - accuracy: 0.9375 - val_loss: 1.5446 - val_accuracy: 0.9750\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4936 - accuracy: 0.9625 - val_loss: 2.9092 - val_accuracy: 0.9750\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7057 - accuracy: 0.9750 - val_loss: 4.6593 - val_accuracy: 0.9500\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4357 - accuracy: 0.9625 - val_loss: 1.8946 - val_accuracy: 0.9750\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6708 - accuracy: 0.9750 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.4406 - accuracy: 0.9500 - val_loss: 2.4162 - val_accuracy: 0.9750\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7073 - accuracy: 0.9187 - val_loss: 5.3302 - val_accuracy: 0.9750\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7944 - accuracy: 0.9500 - val_loss: 2.7024 - val_accuracy: 0.9750\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3134 - accuracy: 0.9812 - val_loss: 2.5653 - val_accuracy: 0.9750\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1190 - accuracy: 0.9812 - val_loss: 4.5938 - val_accuracy: 0.9750\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9703 - accuracy: 0.9625 - val_loss: 0.6042 - val_accuracy: 0.9750\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9116 - accuracy: 0.9500 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 14ms/step - loss: 1.6155 - accuracy: 0.9250 - val_loss: 0.5661 - val_accuracy: 0.9750\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6387 - accuracy: 0.9187 - val_loss: 6.3317 - val_accuracy: 0.9500\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.2447 - accuracy: 0.9062 - val_loss: 1.6113 - val_accuracy: 0.7000\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.1540 - accuracy: 0.7188 - val_loss: 1.8463 - val_accuracy: 0.7750\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.5901 - accuracy: 0.8125 - val_loss: 4.6466 - val_accuracy: 0.8500\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.6147 - accuracy: 0.7625 - val_loss: 5.0341 - val_accuracy: 0.8000\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9900 - accuracy: 0.8188 - val_loss: 2.4238 - val_accuracy: 0.9000\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4035 - accuracy: 0.8125 - val_loss: 2.3827 - val_accuracy: 0.9000\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8674 - accuracy: 0.8125 - val_loss: 5.4044 - val_accuracy: 0.8750\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6823 - accuracy: 0.8313 - val_loss: 1.7460 - val_accuracy: 0.8250\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0472 - accuracy: 0.8250 - val_loss: 2.9647 - val_accuracy: 0.5750\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9274 - accuracy: 0.7937 - val_loss: 5.9295 - val_accuracy: 0.8500\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.6610 - accuracy: 0.7688 - val_loss: 3.8986 - val_accuracy: 0.9500\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9447 - accuracy: 0.8750 - val_loss: 1.3785 - val_accuracy: 0.9000\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5795 - accuracy: 0.9250 - val_loss: 3.5993 - val_accuracy: 0.9000\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0087 - accuracy: 0.8375 - val_loss: 3.5585 - val_accuracy: 0.9500\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0203 - accuracy: 0.8062 - val_loss: 1.8726 - val_accuracy: 0.7500\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.0552 - accuracy: 0.7500 - val_loss: 2.7051 - val_accuracy: 0.9000\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3137 - accuracy: 0.9000 - val_loss: 6.5096 - val_accuracy: 0.6750\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5502 - accuracy: 0.8188 - val_loss: 0.5809 - val_accuracy: 0.8750\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.8784 - accuracy: 0.8875 - val_loss: 0.2657 - val_accuracy: 0.9250\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4188 - accuracy: 0.8687 - val_loss: 3.4409 - val_accuracy: 0.9500\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2535 - accuracy: 0.9375 - val_loss: 1.2811 - val_accuracy: 0.8750\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.7578 - accuracy: 0.8313 - val_loss: 0.1901 - val_accuracy: 0.8500\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 4.8817 - accuracy: 0.8562 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.0856 - accuracy: 0.9625 - val_loss: 10.4630 - val_accuracy: 0.9250\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 7.4389 - accuracy: 0.8625 - val_loss: 7.7610 - val_accuracy: 0.8750\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 5.7337 - accuracy: 0.8687 - val_loss: 45.2716 - val_accuracy: 0.9500\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 28.1201 - accuracy: 0.8625 - val_loss: 0.6690 - val_accuracy: 0.9500\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 5.4891 - accuracy: 0.9125 - val_loss: 4.8079 - val_accuracy: 0.7000\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.9155 - accuracy: 0.8000 - val_loss: 14.3343 - val_accuracy: 0.8750\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 12.1064 - accuracy: 0.8000 - val_loss: 7.3642 - val_accuracy: 0.9000\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.8916 - accuracy: 0.9187 - val_loss: 0.3043 - val_accuracy: 0.8500\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.5642 - accuracy: 0.8313 - val_loss: 5.0324 - val_accuracy: 0.9250\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.9556 - accuracy: 0.8125 - val_loss: 2.1073 - val_accuracy: 0.9500\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8825 - accuracy: 0.8750 - val_loss: 5.9240 - val_accuracy: 0.8500\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.9225 - accuracy: 0.8750 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.5959 - accuracy: 0.9375 - val_loss: 5.2892 - val_accuracy: 0.9750\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 13.7899 - accuracy: 0.9312 - val_loss: 4.4241 - val_accuracy: 0.8500\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.3332 - accuracy: 0.8313 - val_loss: 8.6183 - val_accuracy: 0.8500\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 17.1161 - accuracy: 0.7250 - val_loss: 26.3801 - val_accuracy: 0.9500\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 7.6563 - accuracy: 0.8625 - val_loss: 9.8541 - val_accuracy: 0.8000\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 10.3833 - accuracy: 0.8125 - val_loss: 18.5417 - val_accuracy: 0.8750\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 19.4548 - accuracy: 0.8250 - val_loss: 0.4904 - val_accuracy: 0.7500\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 63.9340 - accuracy: 0.6625 - val_loss: 35.6871 - val_accuracy: 0.8500\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 61.7598 - accuracy: 0.7063 - val_loss: 294.9373 - val_accuracy: 0.7250\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 136.0105 - accuracy: 0.6750 - val_loss: 11.9912 - val_accuracy: 0.6750\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 36.8169 - accuracy: 0.5063 - val_loss: 20.7125 - val_accuracy: 0.8250\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 31.4448 - accuracy: 0.7312 - val_loss: 26.9668 - val_accuracy: 0.8250\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4.3016 - accuracy: 0.7250 - val_loss: 6.8678 - val_accuracy: 0.5000\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.3847 - accuracy: 0.7000 - val_loss: 16.8680 - val_accuracy: 0.8250\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.2388 - accuracy: 0.73 - 0s 13ms/step - loss: 7.7646 - accuracy: 0.7375 - val_loss: 19.1884 - val_accuracy: 0.7750\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 5.0032 - accuracy: 0.7625 - val_loss: 2.3073 - val_accuracy: 0.8250\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.7290 - accuracy: 0.8000 - val_loss: 5.0071 - val_accuracy: 0.8750\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.5676 - accuracy: 0.8062 - val_loss: 3.9458 - val_accuracy: 0.9750\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6853 - accuracy: 0.8813 - val_loss: 2.2762 - val_accuracy: 0.8250\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2705 - accuracy: 0.8438 - val_loss: 0.1642 - val_accuracy: 0.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.7915 - accuracy: 0.8562 - val_loss: 0.3024 - val_accuracy: 0.8750\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.7904 - accuracy: 0.8625 - val_loss: 3.8908 - val_accuracy: 0.9000\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6954 - accuracy: 0.8062 - val_loss: 4.2463 - val_accuracy: 0.9000\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6166 - accuracy: 0.9000 - val_loss: 1.3859 - val_accuracy: 0.8750\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.2414 - accuracy: 0.8375 - val_loss: 1.7006 - val_accuracy: 0.8250\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5680 - accuracy: 0.8188 - val_loss: 4.0251 - val_accuracy: 0.9750\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6946 - accuracy: 0.8875 - val_loss: 4.0873 - val_accuracy: 0.9250\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8351 - accuracy: 0.9312 - val_loss: 7.7723 - val_accuracy: 0.8250\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5782 - accuracy: 0.9062 - val_loss: 1.3584 - val_accuracy: 0.9250\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6470 - accuracy: 0.9062 - val_loss: 2.0994 - val_accuracy: 0.9000\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2983 - accuracy: 0.9125 - val_loss: 2.4709 - val_accuracy: 0.9500\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.9375 - val_loss: 1.8812 - val_accuracy: 0.9750\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5228 - accuracy: 0.9812 - val_loss: 3.2011 - val_accuracy: 0.9250\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0817 - accuracy: 0.9375 - val_loss: 4.1374 - val_accuracy: 0.9500\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2589 - accuracy: 0.9187 - val_loss: 0.0804 - val_accuracy: 0.9750\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3523 - accuracy: 0.9187 - val_loss: 0.0812 - val_accuracy: 0.9750\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.7009 - accuracy: 0.9625 - val_loss: 2.6961 - val_accuracy: 0.9500\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1199 - accuracy: 0.9875 - val_loss: 4.2765 - val_accuracy: 0.9250\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6503 - accuracy: 0.9625 - val_loss: 3.5158 - val_accuracy: 0.9500\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3591 - accuracy: 0.9812 - val_loss: 0.4194 - val_accuracy: 0.9750\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1780 - accuracy: 0.9563 - val_loss: 0.2546 - val_accuracy: 0.9750\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0177 - accuracy: 0.9750 - val_loss: 2.3425 - val_accuracy: 0.9500\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3792 - accuracy: 0.9688 - val_loss: 2.1611 - val_accuracy: 0.9250\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3890 - accuracy: 0.9375 - val_loss: 2.2335 - val_accuracy: 0.9500\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3989 - accuracy: 0.9438 - val_loss: 2.7707 - val_accuracy: 0.9750\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3044 - accuracy: 0.9438 - val_loss: 4.1184 - val_accuracy: 0.9750\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6501 - accuracy: 0.9875 - val_loss: 1.9763 - val_accuracy: 0.9250\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7998 - accuracy: 0.9500 - val_loss: 1.4358 - val_accuracy: 0.9000\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8367 - accuracy: 0.8750 - val_loss: 3.0111 - val_accuracy: 0.9500\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3921 - accuracy: 0.8625 - val_loss: 0.6625 - val_accuracy: 0.9750\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0794 - accuracy: 0.9125 - val_loss: 1.1148 - val_accuracy: 0.9250\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5073 - accuracy: 0.9688 - val_loss: 3.7062 - val_accuracy: 0.9500\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3933 - accuracy: 0.9688 - val_loss: 3.4852 - val_accuracy: 0.9250\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4128 - accuracy: 0.9438 - val_loss: 2.3704 - val_accuracy: 0.9500\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4269 - accuracy: 0.9375 - val_loss: 2.1096 - val_accuracy: 0.9750\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3304 - accuracy: 0.9438 - val_loss: 3.3796 - val_accuracy: 0.9750\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3904 - accuracy: 0.9438 - val_loss: 3.4715 - val_accuracy: 0.9500\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3925 - accuracy: 0.9688 - val_loss: 2.4553 - val_accuracy: 0.9500\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4484 - accuracy: 0.9688 - val_loss: 2.0465 - val_accuracy: 0.9750\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7595 - accuracy: 0.9875 - val_loss: 3.4436 - val_accuracy: 0.9750\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2575 - accuracy: 0.9812 - val_loss: 0.9879 - val_accuracy: 0.9750\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7054 - accuracy: 0.9563 - val_loss: 1.6063 - val_accuracy: 0.9500\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2804 - accuracy: 0.9500 - val_loss: 4.9584 - val_accuracy: 0.9750\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8774 - accuracy: 0.9438 - val_loss: 2.1221 - val_accuracy: 0.9500\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7098 - accuracy: 0.9375 - val_loss: 0.0907 - val_accuracy: 0.9500\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.6442 - accuracy: 0.9563 - val_loss: 0.0555 - val_accuracy: 0.9750\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1346 - accuracy: 0.9563 - val_loss: 3.9923 - val_accuracy: 0.9750\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8512 - accuracy: 0.9937 - val_loss: 6.5254 - val_accuracy: 0.9000\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.8892 - accuracy: 0.9500 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.5621 - accuracy: 0.9625 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.5875 - accuracy: 0.9812 - val_loss: 0.5027 - val_accuracy: 0.9750\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8279 - accuracy: 0.9625 - val_loss: 10.0562 - val_accuracy: 0.9750\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 9.3458 - accuracy: 0.9125 - val_loss: 8.4135 - val_accuracy: 0.9500\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 5.0583 - accuracy: 0.9438 - val_loss: 0.1049 - val_accuracy: 0.9500\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 4.1623 - accuracy: 0.9125 - val_loss: 0.0553 - val_accuracy: 0.9750\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.3847 - accuracy: 0.9312 - val_loss: 4.5221 - val_accuracy: 0.9750\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.4322 - accuracy: 0.9625 - val_loss: 2.2890 - val_accuracy: 0.7250\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step - loss: 2.1287 - accuracy: 0.8687 - val_loss: 0.5666 - val_accuracy: 0.9000\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.2595 - accuracy: 0.9062 - val_loss: 0.1060 - val_accuracy: 0.9500\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0137 - accuracy: 0.8813 - val_loss: 6.2226 - val_accuracy: 0.8750\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.0422 - accuracy: 0.8813 - val_loss: 1.6713 - val_accuracy: 0.9000\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.8734 - accuracy: 0.8813 - val_loss: 0.1119 - val_accuracy: 0.9500\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.5573 - accuracy: 0.8500 - val_loss: 2.0491 - val_accuracy: 0.9250\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2785 - accuracy: 0.8875 - val_loss: 5.8427 - val_accuracy: 0.9500\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1681 - accuracy: 0.9375 - val_loss: 0.8331 - val_accuracy: 0.9250\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.7353 - accuracy: 0.9500 - val_loss: 0.0703 - val_accuracy: 0.9750\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3432 - accuracy: 0.9187 - val_loss: 5.7718 - val_accuracy: 0.9750\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 1.6420 - accuracy: 0.8750 - val_loss: 2.2243 - val_accuracy: 0.9750\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8037 - accuracy: 0.8938 - val_loss: 0.1335 - val_accuracy: 0.9250\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9500 - accuracy: 0.9062 - val_loss: 2.9810 - val_accuracy: 0.9000\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7008 - accuracy: 0.9438 - val_loss: 5.5551 - val_accuracy: 0.9000\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.7429 - accuracy: 0.9000 - val_loss: 0.1799 - val_accuracy: 0.9000\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.7236 - accuracy: 0.8562 - val_loss: 0.1950 - val_accuracy: 0.8500\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.0652 - accuracy: 0.8375 - val_loss: 3.7826 - val_accuracy: 0.9500\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8489 - accuracy: 0.8875 - val_loss: 5.0633 - val_accuracy: 0.9750\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9672 - accuracy: 0.9000 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.7342 - accuracy: 0.8938 - val_loss: 0.0878 - val_accuracy: 0.9750\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9359 - accuracy: 0.8500 - val_loss: 5.0095 - val_accuracy: 0.9750\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2126 - accuracy: 0.8375 - val_loss: 3.9250 - val_accuracy: 0.9250\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3951 - accuracy: 0.8188 - val_loss: 3.9488 - val_accuracy: 0.8000\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 2.4507 - accuracy: 0.8250 - val_loss: 3.8004 - val_accuracy: 0.8500\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.3331 - accuracy: 0.8000 - val_loss: 7.1572 - val_accuracy: 0.7000\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.8160 - accuracy: 0.8438 - val_loss: 0.3463 - val_accuracy: 0.8750\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.2680 - accuracy: 0.7125 - val_loss: 1.1355 - val_accuracy: 0.8500\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1176 - accuracy: 0.8313 - val_loss: 3.0049 - val_accuracy: 0.9000\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3238 - accuracy: 0.9250 - val_loss: 0.9709 - val_accuracy: 0.9000\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0690 - accuracy: 0.8125 - val_loss: 1.8759 - val_accuracy: 0.9750\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7347 - accuracy: 0.9375 - val_loss: 3.2316 - val_accuracy: 0.7000\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3926 - accuracy: 0.9062 - val_loss: 2.6853 - val_accuracy: 0.8250\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.1080 - accuracy: 0.8500 - val_loss: 2.6721 - val_accuracy: 0.9500\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2801 - accuracy: 0.9812 - val_loss: 5.5443 - val_accuracy: 0.7250\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0100 - accuracy: 0.9000 - val_loss: 1.4051 - val_accuracy: 0.9500\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.3496 - accuracy: 0.8750 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.4616 - accuracy: 0.9250 - val_loss: 5.8631 - val_accuracy: 0.8750\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.6676 - accuracy: 0.9187 - val_loss: 2.8412 - val_accuracy: 0.9750\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7011 - accuracy: 0.9438 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.3251 - accuracy: 0.9625 - val_loss: 0.1217 - val_accuracy: 0.9250\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6529 - accuracy: 0.8625 - val_loss: 4.3021 - val_accuracy: 0.9250\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7898 - accuracy: 0.8188 - val_loss: 4.8098 - val_accuracy: 0.9750\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9495 - accuracy: 0.9062 - val_loss: 1.8786 - val_accuracy: 0.8250\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5990 - accuracy: 0.8875 - val_loss: 2.5480 - val_accuracy: 0.9500\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3884 - accuracy: 0.9062 - val_loss: 6.5701 - val_accuracy: 0.9750\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.0506 - accuracy: 0.9125 - val_loss: 1.5766 - val_accuracy: 0.9750\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7336 - accuracy: 0.9125 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2545 - accuracy: 0.8938 - val_loss: 1.0209 - val_accuracy: 0.9250\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4894 - accuracy: 0.9438 - val_loss: 5.4748 - val_accuracy: 0.8750\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2016 - accuracy: 0.8938 - val_loss: 4.1550 - val_accuracy: 0.9500\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8212 - accuracy: 0.9500 - val_loss: 2.1466 - val_accuracy: 0.9500\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4887 - accuracy: 0.9187 - val_loss: 1.6587 - val_accuracy: 0.9500\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1863 - accuracy: 0.9312 - val_loss: 1.4836 - val_accuracy: 0.9000\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4441 - accuracy: 0.8687 - val_loss: 6.1435 - val_accuracy: 0.9000\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.5530 - accuracy: 0.8375 - val_loss: 1.0236 - val_accuracy: 0.8750\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 5.3361 - accuracy: 0.8313 - val_loss: 0.2765 - val_accuracy: 0.8250\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 6.1258 - accuracy: 0.8062 - val_loss: 0.1414 - val_accuracy: 0.9250\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3582 - accuracy: 0.8687 - val_loss: 6.9072 - val_accuracy: 0.9000\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.4975 - accuracy: 0.8375 - val_loss: 3.8729 - val_accuracy: 0.9250\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8902 - accuracy: 0.8562 - val_loss: 0.2730 - val_accuracy: 0.9000\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8997 - accuracy: 0.8188 - val_loss: 3.0943 - val_accuracy: 0.9750\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7493 - accuracy: 0.8313 - val_loss: 3.5844 - val_accuracy: 0.9250\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1774 - accuracy: 0.8687 - val_loss: 3.3846 - val_accuracy: 0.9000\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4877 - accuracy: 0.8438 - val_loss: 0.0733 - val_accuracy: 0.9750\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4544 - accuracy: 0.8313 - val_loss: 3.4806 - val_accuracy: 0.7750\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2776 - accuracy: 0.7812 - val_loss: 4.5568 - val_accuracy: 0.8250\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0964 - accuracy: 0.7750 - val_loss: 2.3470 - val_accuracy: 0.9750\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3861 - accuracy: 0.8250 - val_loss: 0.8364 - val_accuracy: 0.8250\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4162 - accuracy: 0.8250 - val_loss: 3.5974 - val_accuracy: 0.8500\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8358 - accuracy: 0.7625 - val_loss: 1.5858 - val_accuracy: 0.8750\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1688 - accuracy: 0.8125 - val_loss: 2.7094 - val_accuracy: 0.8250\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0547 - accuracy: 0.9187 - val_loss: 5.5608 - val_accuracy: 0.8750\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9274 - accuracy: 0.7875 - val_loss: 0.2169 - val_accuracy: 0.9250\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1024 - accuracy: 0.8875 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.6478 - accuracy: 0.8813 - val_loss: 0.9319 - val_accuracy: 0.9750\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6626 - accuracy: 0.9062 - val_loss: 4.0387 - val_accuracy: 0.9750\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8620 - accuracy: 0.9250 - val_loss: 2.9063 - val_accuracy: 0.9250\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2718 - accuracy: 0.9250 - val_loss: 1.4179 - val_accuracy: 0.8250\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7099 - accuracy: 0.9000 - val_loss: 2.2525 - val_accuracy: 0.9250\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5415 - accuracy: 0.9000 - val_loss: 3.3881 - val_accuracy: 0.9500\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5211 - accuracy: 0.9250 - val_loss: 3.2606 - val_accuracy: 0.9750\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2730 - accuracy: 0.9812 - val_loss: 1.9122 - val_accuracy: 0.9750\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4391 - accuracy: 0.9875 - val_loss: 3.1336 - val_accuracy: 0.9250\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9122 - accuracy: 0.9187 - val_loss: 2.9622 - val_accuracy: 0.9000\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2972 - accuracy: 0.8750 - val_loss: 0.0947 - val_accuracy: 0.9500\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.6163 - accuracy: 0.8500 - val_loss: 1.2187 - val_accuracy: 0.9750\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.5867 - accuracy: 0.8875 - val_loss: 6.3359 - val_accuracy: 0.9500\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.9155 - accuracy: 0.9438 - val_loss: 1.1298 - val_accuracy: 0.8250\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8425 - accuracy: 0.9062 - val_loss: 1.7119 - val_accuracy: 0.9250\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5643 - accuracy: 0.9187 - val_loss: 4.0442 - val_accuracy: 0.9500\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5228 - accuracy: 0.9750 - val_loss: 0.8095 - val_accuracy: 0.9500\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6756 - accuracy: 0.9500 - val_loss: 3.0502 - val_accuracy: 0.9750\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2968 - accuracy: 0.9750 - val_loss: 3.8769 - val_accuracy: 0.9750\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5070 - accuracy: 0.9875 - val_loss: 3.7485 - val_accuracy: 0.9500\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5257 - accuracy: 0.9500 - val_loss: 2.0788 - val_accuracy: 0.9500\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1547 - accuracy: 0.9563 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9084 - accuracy: 0.9438 - val_loss: 3.1096 - val_accuracy: 0.9750\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5104 - accuracy: 0.9312 - val_loss: 5.3744 - val_accuracy: 0.9500\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.2136 - accuracy: 0.9625 - val_loss: 0.1124 - val_accuracy: 0.9500\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.1447 - accuracy: 0.9187 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.8274 - accuracy: 0.9688 - val_loss: 2.3402 - val_accuracy: 0.9500\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5051 - accuracy: 0.9438 - val_loss: 5.3722 - val_accuracy: 0.9750\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.2401 - accuracy: 0.9438 - val_loss: 1.0272 - val_accuracy: 0.9750\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7768 - accuracy: 0.9875 - val_loss: 1.2421 - val_accuracy: 0.9750\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7603 - accuracy: 0.9438 - val_loss: 4.8296 - val_accuracy: 0.9750\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.3437 - accuracy: 0.9688 - val_loss: 1.7343 - val_accuracy: 0.9000\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8164 - accuracy: 0.9312 - val_loss: 0.1794 - val_accuracy: 0.9000\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9559 - accuracy: 0.9125 - val_loss: 3.6417 - val_accuracy: 0.9000\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4304 - accuracy: 0.9062 - val_loss: 4.6012 - val_accuracy: 0.9500\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8922 - accuracy: 0.9000 - val_loss: 1.8730 - val_accuracy: 0.9750\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6074 - accuracy: 0.9875 - val_loss: 1.3288 - val_accuracy: 0.9750\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1582 - accuracy: 0.9688 - val_loss: 4.5163 - val_accuracy: 0.9750\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6292 - accuracy: 0.9812 - val_loss: 2.2433 - val_accuracy: 0.9750\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3043 - accuracy: 0.9875 - val_loss: 2.6525 - val_accuracy: 0.9750\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2373 - accuracy: 0.9875 - val_loss: 3.3060 - val_accuracy: 0.9500\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8202 - accuracy: 0.9500 - val_loss: 1.7667 - val_accuracy: 0.9750\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.5684 - accuracy: 0.9812 - val_loss: 0.0842 - val_accuracy: 0.9500\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6238 - accuracy: 0.9375 - val_loss: 5.9543 - val_accuracy: 0.9750\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.2444 - accuracy: 0.9438 - val_loss: 2.7439 - val_accuracy: 0.9250\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.9825 - accuracy: 0.9062 - val_loss: 0.2151 - val_accuracy: 0.8500\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.4408 - accuracy: 0.8313 - val_loss: 1.6549 - val_accuracy: 0.9500\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.4312 - accuracy: 0.8500 - val_loss: 3.8917 - val_accuracy: 0.9000\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2570 - accuracy: 0.9438 - val_loss: 0.3139 - val_accuracy: 0.8500\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2.9808 - accuracy: 0.8625 - val_loss: 0.0755 - val_accuracy: 0.9500\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1531 - accuracy: 0.9250 - val_loss: 4.1696 - val_accuracy: 0.9500\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.4965 - accuracy: 0.8938 - val_loss: 2.1661 - val_accuracy: 0.9500\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.6492 - accuracy: 0.9000 - val_loss: 0.1185 - val_accuracy: 0.9500\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.9136 - accuracy: 0.8750 - val_loss: 0.3626 - val_accuracy: 0.9750\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0771 - accuracy: 0.9312 - val_loss: 4.0231 - val_accuracy: 0.9500\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.4783 - accuracy: 0.9500 - val_loss: 1.3963 - val_accuracy: 0.9250\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.6271 - accuracy: 0.9438 - val_loss: 2.2212 - val_accuracy: 0.9500\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4444 - accuracy: 0.9125 - val_loss: 4.7053 - val_accuracy: 0.9500\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6523 - accuracy: 0.9875 - val_loss: 2.1532 - val_accuracy: 0.9250\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3863 - accuracy: 0.9375 - val_loss: 2.1688 - val_accuracy: 0.9750\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3377 - accuracy: 0.9937 - val_loss: 3.8357 - val_accuracy: 0.9750\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5150 - accuracy: 0.9937 - val_loss: 3.3175 - val_accuracy: 0.9750\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2477 - accuracy: 0.9875 - val_loss: 1.6368 - val_accuracy: 0.9750\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6369 - accuracy: 0.9563 - val_loss: 2.4909 - val_accuracy: 0.9750\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 5.6129 - val_accuracy: 0.9500\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9593 - accuracy: 0.9563 - val_loss: 0.3860 - val_accuracy: 0.9750\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.7638 - accuracy: 0.9688 - val_loss: 0.0829 - val_accuracy: 0.9500\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.7129 - accuracy: 0.9438 - val_loss: 1.0255 - val_accuracy: 0.9750\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0966 - accuracy: 0.9875 - val_loss: 5.5951 - val_accuracy: 0.9750\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 1.4806 - accuracy: 0.9688 - val_loss: 2.4709 - val_accuracy: 0.9500\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3084 - accuracy: 0.9812 - val_loss: 1.6823 - val_accuracy: 0.9250\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4053 - accuracy: 0.9438 - val_loss: 3.8374 - val_accuracy: 0.9750\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.4240 - accuracy: 0.9812 - val_loss: 3.8043 - val_accuracy: 0.9500\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3205 - accuracy: 0.9688 - val_loss: 2.3087 - val_accuracy: 0.9750\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3998 - accuracy: 0.9812 - val_loss: 1.9798 - val_accuracy: 0.9750\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3472 - accuracy: 0.9937 - val_loss: 3.8199 - val_accuracy: 0.9750\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7319 - accuracy: 0.9812 - val_loss: 1.5019 - val_accuracy: 0.9500\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3599 - accuracy: 0.9312 - val_loss: 0.0965 - val_accuracy: 0.9500\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.4296 - accuracy: 0.9250 - val_loss: 4.3650 - val_accuracy: 0.9750\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8071 - accuracy: 0.9625 - val_loss: 2.7064 - val_accuracy: 0.9500\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0703 - accuracy: 0.9250 - val_loss: 0.1601 - val_accuracy: 0.9250\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.1183 - accuracy: 0.8500 - val_loss: 0.7685 - val_accuracy: 0.9500\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.0939 - accuracy: 0.9000 - val_loss: 4.3393 - val_accuracy: 0.9500\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3764 - accuracy: 0.9750 - val_loss: 0.1721 - val_accuracy: 0.9250\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.6398 - accuracy: 0.8750 - val_loss: 0.6765 - val_accuracy: 0.9750\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1678 - accuracy: 0.9375 - val_loss: 5.7283 - val_accuracy: 0.9750\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3516 - accuracy: 0.9250 - val_loss: 1.3464 - val_accuracy: 0.9750\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6153 - accuracy: 0.9563 - val_loss: 0.0771 - val_accuracy: 0.9750\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.1124 - accuracy: 0.9563 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.0385 - accuracy: 0.9187 - val_loss: 5.4120 - val_accuracy: 0.9750\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6732 - accuracy: 0.9625 - val_loss: 0.6941 - val_accuracy: 0.9000\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0067 - accuracy: 0.9625 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2673 - accuracy: 0.9500 - val_loss: 1.5422 - val_accuracy: 0.9750\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8283 - accuracy: 0.9812 - val_loss: 3.4481 - val_accuracy: 0.9750\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.6279 - accuracy: 0.9500 - val_loss: 0.4751 - val_accuracy: 0.9750\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9067 - accuracy: 0.9625 - val_loss: 1.6410 - val_accuracy: 0.9750\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2888 - accuracy: 0.9563 - val_loss: 4.6340 - val_accuracy: 0.9750\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6672 - accuracy: 0.9750 - val_loss: 1.9834 - val_accuracy: 0.9750\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6033 - accuracy: 0.9812 - val_loss: 1.2391 - val_accuracy: 0.9750\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2552 - accuracy: 0.9688 - val_loss: 4.7838 - val_accuracy: 0.9750\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.1832 - accuracy: 0.9438 - val_loss: 3.6802 - val_accuracy: 0.9750\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3805 - accuracy: 0.9625 - val_loss: 2.7097 - val_accuracy: 0.9250\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2235 - accuracy: 0.9500 - val_loss: 4.8171 - val_accuracy: 0.9500\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7671 - accuracy: 0.9187 - val_loss: 2.6616 - val_accuracy: 0.9750\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4547 - accuracy: 0.9375 - val_loss: 1.2478 - val_accuracy: 0.9750\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7489 - accuracy: 0.9250 - val_loss: 3.0881 - val_accuracy: 0.9750\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3395 - accuracy: 0.9187 - val_loss: 4.0466 - val_accuracy: 0.9750\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4618 - accuracy: 0.9625 - val_loss: 2.7203 - val_accuracy: 0.9250\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3475 - accuracy: 0.9750 - val_loss: 3.1409 - val_accuracy: 0.9000\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3564 - accuracy: 0.9125 - val_loss: 3.7966 - val_accuracy: 0.9250\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5060 - accuracy: 0.9000 - val_loss: 3.5529 - val_accuracy: 0.9500\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3529 - accuracy: 0.9312 - val_loss: 2.7208 - val_accuracy: 0.9750\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3403 - accuracy: 0.9625 - val_loss: 1.9902 - val_accuracy: 0.9750\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4893 - accuracy: 0.9750 - val_loss: 3.1765 - val_accuracy: 0.9250\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2828 - accuracy: 0.9750 - val_loss: 4.0549 - val_accuracy: 0.9500\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6214 - accuracy: 0.9250 - val_loss: 3.5203 - val_accuracy: 0.9250\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3779 - accuracy: 0.9125 - val_loss: 4.0375 - val_accuracy: 0.9500\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4741 - accuracy: 0.9500 - val_loss: 2.0159 - val_accuracy: 0.9750\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4708 - accuracy: 0.9438 - val_loss: 1.6643 - val_accuracy: 0.9750\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4094 - accuracy: 0.9750 - val_loss: 3.4990 - val_accuracy: 0.9500\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.9750 - val_loss: 3.5249 - val_accuracy: 0.9250\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.9438 - val_loss: 3.5410 - val_accuracy: 0.9500\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3575 - accuracy: 0.9438 - val_loss: 0.0630 - val_accuracy: 0.9750\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3580 - accuracy: 0.9312 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1349 - accuracy: 0.9812 - val_loss: 2.6260 - val_accuracy: 0.9500\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0939 - accuracy: 0.9563 - val_loss: 5.5824 - val_accuracy: 0.9750\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.2471 - accuracy: 0.9688 - val_loss: 1.5684 - val_accuracy: 0.9500\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4854 - accuracy: 0.9688 - val_loss: 0.6619 - val_accuracy: 0.9500\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.8558 - accuracy: 0.9625 - val_loss: 2.3639 - val_accuracy: 0.9500\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0621 - accuracy: 0.9625 - val_loss: 4.3898 - val_accuracy: 0.9750\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5480 - accuracy: 0.9875 - val_loss: 0.7836 - val_accuracy: 0.9500\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6784 - accuracy: 0.9563 - val_loss: 3.1601 - val_accuracy: 0.9750\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7446 - accuracy: 0.9500 - val_loss: 1.5785 - val_accuracy: 0.9500\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2774 - accuracy: 0.9062 - val_loss: 0.1066 - val_accuracy: 0.9500\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8937 - accuracy: 0.9312 - val_loss: 3.6676 - val_accuracy: 0.9500\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6832 - accuracy: 0.9187 - val_loss: 4.6116 - val_accuracy: 0.9500\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7862 - accuracy: 0.9375 - val_loss: 0.0722 - val_accuracy: 0.9750\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3080 - accuracy: 0.9750 - val_loss: 0.9346 - val_accuracy: 0.9750\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7104 - accuracy: 0.9750 - val_loss: 4.5617 - val_accuracy: 0.9750\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5854 - accuracy: 0.9750 - val_loss: 2.5620 - val_accuracy: 0.9500\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5167 - accuracy: 0.9812 - val_loss: 1.7747 - val_accuracy: 0.9250\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2627 - accuracy: 0.9500 - val_loss: 4.3485 - val_accuracy: 0.9500\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6716 - accuracy: 0.9563 - val_loss: 3.9934 - val_accuracy: 0.9750\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.9937 - val_loss: 0.3874 - val_accuracy: 0.9750\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9657 - accuracy: 0.9750 - val_loss: 0.7190 - val_accuracy: 0.9750\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5620 - accuracy: 0.9750 - val_loss: 4.1120 - val_accuracy: 0.9750\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.0929 - accuracy: 0.9438 - val_loss: 5.5915 - val_accuracy: 0.9500\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2056 - accuracy: 0.9563 - val_loss: 0.1185 - val_accuracy: 0.9500\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.0891 - accuracy: 0.8875 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9049 - accuracy: 0.9125 - val_loss: 5.5647 - val_accuracy: 0.9750\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.3917 - accuracy: 0.9563 - val_loss: 4.1565 - val_accuracy: 0.9000\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1348 - accuracy: 0.9625 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.8799 - accuracy: 0.9250 - val_loss: 0.5142 - val_accuracy: 0.9750\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6047 - accuracy: 0.9937 - val_loss: 4.7653 - val_accuracy: 0.9750\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 19ms/step - loss: 1.5988 - accuracy: 0.9438 - val_loss: 2.2753 - val_accuracy: 0.9750\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4669 - accuracy: 0.9937 - val_loss: 0.8635 - val_accuracy: 0.9750\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6475 - accuracy: 0.9875 - val_loss: 3.2846 - val_accuracy: 0.9750\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3043 - accuracy: 0.9812 - val_loss: 4.1539 - val_accuracy: 0.9750\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6326 - accuracy: 0.9812 - val_loss: 1.6585 - val_accuracy: 0.9750\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5339 - accuracy: 0.9875 - val_loss: 1.3492 - val_accuracy: 0.9750\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4456 - accuracy: 0.9563 - val_loss: 4.6009 - val_accuracy: 0.9500\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.0981 - accuracy: 0.9563 - val_loss: 2.1873 - val_accuracy: 0.8750\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1980 - accuracy: 0.9000 - val_loss: 0.0805 - val_accuracy: 0.9750\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2711 - accuracy: 0.9375 - val_loss: 3.0619 - val_accuracy: 0.9250\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7930 - accuracy: 0.9750 - val_loss: 3.4808 - val_accuracy: 0.9500\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4504 - accuracy: 0.9625 - val_loss: 2.2109 - val_accuracy: 0.9750\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2647 - accuracy: 0.9563 - val_loss: 3.4950 - val_accuracy: 0.9750\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5891 - accuracy: 0.9312 - val_loss: 2.7851 - val_accuracy: 0.9750\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3173 - accuracy: 0.9438 - val_loss: 3.1615 - val_accuracy: 0.9250\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5194 - accuracy: 0.9563 - val_loss: 3.6401 - val_accuracy: 0.9250\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4852 - accuracy: 0.9500 - val_loss: 2.5288 - val_accuracy: 0.9750\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2604 - accuracy: 0.9812 - val_loss: 0.5135 - val_accuracy: 0.9500\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8597 - accuracy: 0.9625 - val_loss: 2.6753 - val_accuracy: 0.9750\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1798 - accuracy: 0.9875 - val_loss: 4.7682 - val_accuracy: 0.9750\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6678 - accuracy: 0.9875 - val_loss: 2.3043 - val_accuracy: 0.9750\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3071 - accuracy: 0.9875 - val_loss: 1.4723 - val_accuracy: 0.9750\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4426 - accuracy: 0.9812 - val_loss: 2.6861 - val_accuracy: 0.9500\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2963 - accuracy: 0.9375 - val_loss: 2.9873 - val_accuracy: 0.9750\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4455 - accuracy: 0.9563 - val_loss: 2.1448 - val_accuracy: 0.9750\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3690 - accuracy: 0.9688 - val_loss: 0.4368 - val_accuracy: 0.9750\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0848 - accuracy: 0.9250 - val_loss: 1.7319 - val_accuracy: 0.9750\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6258 - accuracy: 0.8875 - val_loss: 3.5568 - val_accuracy: 0.9750\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5749 - accuracy: 0.9125 - val_loss: 2.7564 - val_accuracy: 0.9000\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3621 - accuracy: 0.9563 - val_loss: 3.4915 - val_accuracy: 0.9250\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7284 - accuracy: 0.8750 - val_loss: 3.7609 - val_accuracy: 0.9500\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5195 - accuracy: 0.9312 - val_loss: 3.7642 - val_accuracy: 0.9750\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5885 - accuracy: 0.9875 - val_loss: 2.8732 - val_accuracy: 0.9500\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9838 - accuracy: 0.9438 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.7841 - accuracy: 0.9438 - val_loss: 1.6871 - val_accuracy: 0.9750\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2288 - accuracy: 0.9688 - val_loss: 4.7233 - val_accuracy: 0.9500\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3235 - accuracy: 0.9750 - val_loss: 2.5515 - val_accuracy: 0.9750\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4243 - accuracy: 0.9875 - val_loss: 1.6806 - val_accuracy: 0.9500\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3053 - accuracy: 0.9563 - val_loss: 4.6133 - val_accuracy: 0.9750\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6655 - accuracy: 0.9563 - val_loss: 2.6872 - val_accuracy: 0.9750\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3745 - accuracy: 0.9812 - val_loss: 1.7863 - val_accuracy: 0.9750\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4398 - accuracy: 0.9750 - val_loss: 2.0246 - val_accuracy: 0.9500\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9716 - accuracy: 0.9688 - val_loss: 2.0872 - val_accuracy: 0.9750\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3780 - accuracy: 0.9688 - val_loss: 4.7769 - val_accuracy: 0.9750\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6222 - accuracy: 0.9937 - val_loss: 3.2700 - val_accuracy: 0.9750\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3165 - accuracy: 0.9750 - val_loss: 1.3852 - val_accuracy: 0.9750\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2451 - accuracy: 0.9812 - val_loss: 2.0134 - val_accuracy: 0.9750\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3026 - accuracy: 0.9563 - val_loss: 4.6557 - val_accuracy: 0.9500\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6309 - accuracy: 0.9438 - val_loss: 1.1106 - val_accuracy: 0.9500\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.3148 - accuracy: 0.9375 - val_loss: 1.2165 - val_accuracy: 0.9750\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7357 - accuracy: 0.9500 - val_loss: 5.7664 - val_accuracy: 0.9750\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1804 - accuracy: 0.9750 - val_loss: 0.8842 - val_accuracy: 0.9750\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2952 - accuracy: 0.9812 - val_loss: 0.0881 - val_accuracy: 0.9750\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6998 - accuracy: 0.9688 - val_loss: 3.6507 - val_accuracy: 0.9750\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4406 - accuracy: 0.9625 - val_loss: 4.5398 - val_accuracy: 0.9750\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5654 - accuracy: 0.9875 - val_loss: 0.7735 - val_accuracy: 0.9500\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7543 - accuracy: 0.9563 - val_loss: 2.8433 - val_accuracy: 0.9750\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1988 - accuracy: 0.9812 - val_loss: 5.5168 - val_accuracy: 0.9500\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0681 - accuracy: 0.9250 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.4301 - accuracy: 0.9438 - val_loss: 0.0782 - val_accuracy: 0.9500\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6002 - accuracy: 0.9625 - val_loss: 4.9192 - val_accuracy: 0.9500\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.0963 - accuracy: 0.9312 - val_loss: 4.3747 - val_accuracy: 0.9750\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5602 - accuracy: 0.9875 - val_loss: 0.9111 - val_accuracy: 0.9250\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5833 - accuracy: 0.9438 - val_loss: 4.3665 - val_accuracy: 0.9750\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5757 - accuracy: 0.9500 - val_loss: 2.8011 - val_accuracy: 0.9750\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5057 - accuracy: 0.9750 - val_loss: 3.6953 - val_accuracy: 0.9250\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.1771 - accuracy: 0.9563 - val_loss: 5.0541 - val_accuracy: 0.9250\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4997 - accuracy: 0.9187 - val_loss: 0.9818 - val_accuracy: 0.9750\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.6892 - accuracy: 0.9375 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.9890 - accuracy: 0.9688 - val_loss: 6.7584 - val_accuracy: 0.9500\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.2129 - accuracy: 0.9187 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.5510 - accuracy: 0.9375 - val_loss: 0.0639 - val_accuracy: 0.9750\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.7927 - accuracy: 0.9750 - val_loss: 1.0414 - val_accuracy: 0.9500\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1208 - accuracy: 0.9563 - val_loss: 5.8155 - val_accuracy: 0.9250\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.4558 - accuracy: 0.9438 - val_loss: 3.7848 - val_accuracy: 0.8500\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3643 - accuracy: 0.9563 - val_loss: 0.0774 - val_accuracy: 0.9750\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.7456 - accuracy: 0.9062 - val_loss: 0.0435 - val_accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2288 - accuracy: 0.9750 - val_loss: 5.6223 - val_accuracy: 0.9500\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.4510 - accuracy: 0.9125 - val_loss: 0.9772 - val_accuracy: 0.9500\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 1.3493 - accuracy: 0.93 - 0s 12ms/step - loss: 1.9013 - accuracy: 0.8875 - val_loss: 0.9816 - val_accuracy: 0.9000\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.5284 - accuracy: 0.8625 - val_loss: 0.1475 - val_accuracy: 0.9000\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.5422 - accuracy: 0.8000 - val_loss: 4.6932 - val_accuracy: 0.8500\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2886 - accuracy: 0.7563 - val_loss: 1.4424 - val_accuracy: 0.8500\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.4335 - accuracy: 0.7750 - val_loss: 0.8060 - val_accuracy: 0.7500\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6112 - accuracy: 0.7312 - val_loss: 4.7254 - val_accuracy: 0.8750\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.6482 - accuracy: 0.7625 - val_loss: 4.1602 - val_accuracy: 0.8750\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3446 - accuracy: 0.8188 - val_loss: 3.1881 - val_accuracy: 0.8000\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4073 - accuracy: 0.7250 - val_loss: 2.1385 - val_accuracy: 0.8750\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.5587 - accuracy: 0.8062 - val_loss: 1.6876 - val_accuracy: 0.8500\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.8618 - accuracy: 0.7437 - val_loss: 4.5804 - val_accuracy: 0.9250\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.5484 - accuracy: 0.7937 - val_loss: 3.3423 - val_accuracy: 0.6250\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6675 - accuracy: 0.6812 - val_loss: 4.9640 - val_accuracy: 0.7250\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.5125 - accuracy: 0.7063 - val_loss: 5.2045 - val_accuracy: 0.6750\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.8267 - accuracy: 0.7688 - val_loss: 4.5974 - val_accuracy: 0.8250\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.0956 - accuracy: 0.7250 - val_loss: 3.5068 - val_accuracy: 0.9250\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3940 - accuracy: 0.8438 - val_loss: 4.8780 - val_accuracy: 0.7500\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.6112 - accuracy: 0.7500 - val_loss: 3.0517 - val_accuracy: 0.7250\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2573 - accuracy: 0.7812 - val_loss: 4.9105 - val_accuracy: 0.8750\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0399 - accuracy: 0.8562 - val_loss: 3.4106 - val_accuracy: 0.9000\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.9017 - accuracy: 0.8813 - val_loss: 0.6284 - val_accuracy: 0.8750\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.3151 - accuracy: 0.7688 - val_loss: 1.1465 - val_accuracy: 0.8750\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.8042 - accuracy: 0.8250 - val_loss: 3.7086 - val_accuracy: 0.9500\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8788 - accuracy: 0.8438 - val_loss: 3.8135 - val_accuracy: 0.9500\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3857 - accuracy: 0.9125 - val_loss: 2.3390 - val_accuracy: 0.9250\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8511 - accuracy: 0.9500 - val_loss: 2.7108 - val_accuracy: 0.9500\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7238 - accuracy: 0.9500 - val_loss: 3.7832 - val_accuracy: 0.9500\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9297 - accuracy: 0.8750 - val_loss: 0.0890 - val_accuracy: 0.9500\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1716 - accuracy: 0.9000 - val_loss: 1.5188 - val_accuracy: 0.9000\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5367 - accuracy: 0.9250 - val_loss: 2.3420 - val_accuracy: 0.9000\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8780 - accuracy: 0.8875 - val_loss: 3.0193 - val_accuracy: 0.8750\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1305 - accuracy: 0.8438 - val_loss: 3.9469 - val_accuracy: 0.9000\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7866 - accuracy: 0.8062 - val_loss: 1.7297 - val_accuracy: 0.9750\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4173 - accuracy: 0.8750 - val_loss: 4.8899 - val_accuracy: 0.8750\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1946 - accuracy: 0.8188 - val_loss: 2.3400 - val_accuracy: 0.8000\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7972 - accuracy: 0.8438 - val_loss: 2.4116 - val_accuracy: 0.8000\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0298 - accuracy: 0.7812 - val_loss: 4.0413 - val_accuracy: 0.9250\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2116 - accuracy: 0.7563 - val_loss: 2.1334 - val_accuracy: 0.9000\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.2839 - accuracy: 0.8375 - val_loss: 0.8197 - val_accuracy: 0.8250\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.8339 - accuracy: 0.8438 - val_loss: 1.6370 - val_accuracy: 0.9000\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4154 - accuracy: 0.8687 - val_loss: 3.6244 - val_accuracy: 0.7500\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6844 - accuracy: 0.8250 - val_loss: 2.4283 - val_accuracy: 0.8750\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9713 - accuracy: 0.8250 - val_loss: 1.5051 - val_accuracy: 0.9500\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5768 - accuracy: 0.8438 - val_loss: 5.2725 - val_accuracy: 0.9250\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0653 - accuracy: 0.8562 - val_loss: 3.2046 - val_accuracy: 0.9500\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8086 - accuracy: 0.8625 - val_loss: 3.0560 - val_accuracy: 0.9500\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4217 - accuracy: 0.8687 - val_loss: 4.9845 - val_accuracy: 0.9500\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3823 - accuracy: 0.8813 - val_loss: 0.6280 - val_accuracy: 0.9000\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2186 - accuracy: 0.9125 - val_loss: 0.1376 - val_accuracy: 0.9500\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9576 - accuracy: 0.8687 - val_loss: 4.6535 - val_accuracy: 0.9500\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9138 - accuracy: 0.9000 - val_loss: 1.1048 - val_accuracy: 0.9000\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.6905 - accuracy: 0.8500 - val_loss: 0.3981 - val_accuracy: 0.9250\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 4.8827 - accuracy: 0.8562 - val_loss: 0.9101 - val_accuracy: 0.9250\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4580 - accuracy: 0.8813 - val_loss: 6.9316 - val_accuracy: 0.9500\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 2.3078 - accuracy: 0.8375 - val_loss: 0.0547 - val_accuracy: 0.9750\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 5.5213 - accuracy: 0.9062 - val_loss: 0.0839 - val_accuracy: 0.9500\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.8108 - accuracy: 0.9375 - val_loss: 6.8691 - val_accuracy: 0.9250\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 4.4620 - accuracy: 0.9000 - val_loss: 4.8734 - val_accuracy: 0.9500\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2124 - accuracy: 0.9937 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 6.8773 - accuracy: 0.9312 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 2.3027 - accuracy: 0.9438 - val_loss: 2.6804 - val_accuracy: 0.9500\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.8627 - accuracy: 0.9438 - val_loss: 2.0214 - val_accuracy: 0.9000\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1903 - accuracy: 0.9250 - val_loss: 0.0702 - val_accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.6853 - accuracy: 0.9000 - val_loss: 1.2985 - val_accuracy: 0.9500\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.7089 - accuracy: 0.9688 - val_loss: 5.4800 - val_accuracy: 0.9500\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0220 - accuracy: 0.9500 - val_loss: 2.0802 - val_accuracy: 0.9750\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7781 - accuracy: 0.9875 - val_loss: 1.2381 - val_accuracy: 0.9750\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0472 - accuracy: 0.9438 - val_loss: 3.3940 - val_accuracy: 0.9500\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3642 - accuracy: 0.9125 - val_loss: 0.4286 - val_accuracy: 0.9750\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.9837 - accuracy: 0.9187 - val_loss: 1.6785 - val_accuracy: 0.9000\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3272 - accuracy: 0.9375 - val_loss: 6.2717 - val_accuracy: 0.9500\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.7342 - accuracy: 0.9438 - val_loss: 1.2200 - val_accuracy: 0.9500\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0832 - accuracy: 0.9563 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 4.1365 - accuracy: 0.9812 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3287 - accuracy: 0.9875 - val_loss: 2.9908 - val_accuracy: 0.9750\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.5417 - accuracy: 0.9688 - val_loss: 6.0627 - val_accuracy: 0.9500\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.4755 - accuracy: 0.8875 - val_loss: 0.0916 - val_accuracy: 0.9500\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 5.3054 - accuracy: 0.8313 - val_loss: 0.0873 - val_accuracy: 0.9750\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.9346 - accuracy: 0.9375 - val_loss: 10.5112 - val_accuracy: 0.8750\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 12.6406 - accuracy: 0.8250 - val_loss: 18.4096 - val_accuracy: 0.9000\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 9.4277 - accuracy: 0.9000 - val_loss: 39.9635 - val_accuracy: 0.9500\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 34.4393 - accuracy: 0.9062 - val_loss: 3.2947 - val_accuracy: 0.9750\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 8.4171 - accuracy: 0.9500 - val_loss: 91.1994 - val_accuracy: 0.9250\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 48.5397 - accuracy: 0.7937 - val_loss: 72.5858 - val_accuracy: 0.7750\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 55.7776 - accuracy: 0.6062 - val_loss: 122.9693 - val_accuracy: 0.7000\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 79.6291 - accuracy: 0.6375 - val_loss: 15.3438 - val_accuracy: 0.7750\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 27.9241 - accuracy: 0.6062 - val_loss: 32.6509 - val_accuracy: 0.8000\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 67.4230 - accuracy: 0.609 - 0s 17ms/step - loss: 47.5946 - accuracy: 0.6938 - val_loss: 245.7329 - val_accuracy: 0.6250\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 110.5609 - accuracy: 0.6375 - val_loss: 4.4581 - val_accuracy: 0.8500\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 42.3882 - accuracy: 0.6500 - val_loss: 17.0669 - val_accuracy: 0.8000\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 31.4777 - accuracy: 0.6500 - val_loss: 185.6826 - val_accuracy: 0.6750\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 87.2958 - accuracy: 0.7125 - val_loss: 0.4322 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 21.8086 - accuracy: 0.6500 - val_loss: 9.6475 - val_accuracy: 0.9500\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 13.6739 - accuracy: 0.7875 - val_loss: 40.5737 - val_accuracy: 0.7250\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 5.4829 - accuracy: 0.8562 - val_loss: 0.2006 - val_accuracy: 0.9000\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 26.4884 - accuracy: 0.7563 - val_loss: 0.2010 - val_accuracy: 0.8500\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.0341 - accuracy: 0.8375 - val_loss: 17.0991 - val_accuracy: 0.9250\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 7.2200 - accuracy: 0.8375 - val_loss: 7.7014 - val_accuracy: 0.9750\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.2829 - accuracy: 0.9500 - val_loss: 3.6690 - val_accuracy: 0.9500\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 6.0541 - accuracy: 0.8625 - val_loss: 33.3508 - val_accuracy: 0.8250\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 22.1567 - accuracy: 0.8062 - val_loss: 41.8857 - val_accuracy: 0.9500\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 10.2881 - accuracy: 0.9250 - val_loss: 3.9539 - val_accuracy: 0.9250\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 17.8795 - accuracy: 0.8375 - val_loss: 40.6788 - val_accuracy: 0.9250\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 41.0768 - accuracy: 0.9250 - val_loss: 54.4500 - val_accuracy: 0.9000\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 12.3669 - accuracy: 0.8875 - val_loss: 19.7206 - val_accuracy: 0.9000\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 26.0454 - accuracy: 0.8250 - val_loss: 32.1795 - val_accuracy: 0.9250\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 28.5000 - accuracy: 0.8875 - val_loss: 36.2956 - val_accuracy: 0.8000\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.2354 - accuracy: 0.8250 - val_loss: 7.5951 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 7.7698 - accuracy: 0.7125 - val_loss: 67.4908 - val_accuracy: 0.8750\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 40.6071 - accuracy: 0.8062 - val_loss: 22.7470 - val_accuracy: 0.8500\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 26.3036 - accuracy: 0.8188 - val_loss: 2.4870 - val_accuracy: 0.9500\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 8.5469 - accuracy: 0.8000 - val_loss: 84.2999 - val_accuracy: 0.9000\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 51.1888 - accuracy: 0.8625 - val_loss: 30.6015 - val_accuracy: 0.9500\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 14.5342 - accuracy: 0.7937 - val_loss: 0.0793 - val_accuracy: 0.9750\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2065 - accuracy: 0.8750 - val_loss: 37.2498 - val_accuracy: 0.7750\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 12.0121 - accuracy: 0.7937 - val_loss: 10.9212 - val_accuracy: 0.8500\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 8.1664 - accuracy: 0.8000 - val_loss: 1.0817 - val_accuracy: 0.8250\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 8.2729 - accuracy: 0.7125 - val_loss: 3.5812 - val_accuracy: 0.9500\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3126 - accuracy: 0.8562 - val_loss: 37.9989 - val_accuracy: 0.8500\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 16.6924 - accuracy: 0.7750 - val_loss: 16.2563 - val_accuracy: 0.8000\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.7988 - accuracy: 0.7625 - val_loss: 0.0964 - val_accuracy: 0.9500\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 9.8661 - accuracy: 0.7937 - val_loss: 0.2515 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "num_epochs=1000\n",
    "\n",
    "history = model.fit(x_train, y,validation_data=(x_test, target_test), epochs=num_epochs,batch_size=64,verbose=1)\n",
    "#alvarito\n",
    "#history = model.fit(x_train, y, epochs=num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, num_epochs+1)\n",
    "\n",
    "# during training\n",
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "\n",
    "# outside training\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficas de loss\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficas de accuracy\n",
    "plt.plot(epochs, accuracy, 'r')\n",
    "plt.plot(epochs, val_accuracy, 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 5.2158 - accuracy: 0.7437\n",
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "    0  1  2  3  4  5\n",
      "0   0  0  0  0  0  1\n",
      "1   0  0  0  1  0  0\n",
      "2   1  0  0  0  0  0\n",
      "3   0  0  0  0  1  0\n",
      "4   0  0  0  0  0  1\n",
      "5   0  0  0  0  0  1\n",
      "6   0  0  1  0  0  0\n",
      "7   0  0  1  0  0  0\n",
      "8   1  0  0  0  0  0\n",
      "9   0  1  0  0  0  0\n",
      "10  0  0  0  0  0  1\n",
      "11  0  0  1  0  0  0\n",
      "12  0  0  0  0  0  1\n",
      "13  0  0  1  0  0  0\n",
      "14  0  0  0  0  0  1\n",
      "15  0  0  0  0  1  0\n",
      "16  0  0  0  1  0  0\n",
      "17  1  0  0  0  0  0\n",
      "18  0  0  1  0  0  0\n",
      "19  0  0  0  1  0  0\n",
      "20  0  0  1  0  0  0\n",
      "21  0  0  0  0  0  1\n",
      "22  0  0  0  0  0  1\n",
      "23  0  0  1  0  0  0\n",
      "24  1  0  0  0  0  0\n",
      "25  0  0  0  0  1  0\n",
      "26  0  1  0  0  0  0\n",
      "27  0  0  1  0  0  0\n",
      "28  0  0  1  0  0  0\n",
      "29  0  0  0  1  0  0\n",
      "30  0  0  0  1  0  0\n",
      "31  0  0  0  1  0  0\n",
      "32  1  0  0  0  0  0\n",
      "33  0  0  0  0  0  1\n",
      "34  0  1  0  0  0  0\n",
      "35  0  0  0  0  1  0\n",
      "36  0  0  1  0  0  0\n",
      "37  0  0  0  1  0  0\n",
      "38  1  0  0  0  0  0\n",
      "39  0  1  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "# evaluamos el modelo\n",
    "scores = model.evaluate(x_train, y)\n",
    " \n",
    "    \n",
    "y_t = []\n",
    "ls = []\n",
    "for i in y_test:\n",
    "    ls = [0 for i in range(6)]\n",
    "    ls[i] = 1\n",
    "    y_t.append(ls)\n",
    "y_t = pd.DataFrame(y_t)\n",
    "y_predicted = model.predict(x_test).round()\n",
    "print (y_predicted)\n",
    "print (y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de pruebas: 40\n",
      "Cantidad total de aciertos: 0\n",
      "Porcentaje de aciertos: 0.0%\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "[3, 5, 0, 3, 1, 5, 1, 4, 4, 3, 0, 3, 5, 5, 0, 3, 5, 2, 1, 1, 0, 1, 3, 2, 4, 0, 5, 2, 3, 4, 3, 2, 3, 1, 0, 3, 5, 5, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "def convert_at_type_array(mat):\n",
    "    types = []\n",
    "    for row in mat:\n",
    "        value = 0\n",
    "        for index in row:\n",
    "            if (index >= 1):\n",
    "                break\n",
    "            value += 1\n",
    "        types.append(value)\n",
    "    return types\n",
    "\n",
    "def stadistics(y_real, y_predicted):\n",
    "    counter = 0\n",
    "    total = len(y_real)\n",
    "    for i in range(total):\n",
    "        if (y_real[i] == y_predicted[i]):\n",
    "            counter += 1\n",
    "    print(f\"Cantidad total de pruebas: {total}\")\n",
    "    print(f\"Cantidad total de aciertos: {counter}\")\n",
    "    print(f\"Porcentaje de aciertos: {counter/total*100}%\")\n",
    "\n",
    "    \n",
    "stadistics(convert_at_type_array(y_predicted),convert_at_type_array(y_t.to_numpy()))\n",
    "\n",
    "print(convert_at_type_array(y_predicted))\n",
    "print(convert_at_type_array(y_t.to_numpy())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"nombre_11_10_21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Guardado!\n"
     ]
    }
   ],
   "source": [
    "# serializar el modelo a JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"./jsons/\"+name+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serializar los pesos a HDF5\n",
    "model.save_weights(\"./h_fives/\"+name+\".h5\")\n",
    "print(\"Modelo Guardado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ver\n",
    "#https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado modelo desde disco.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open(\"./jsons/\"+name+'.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# cargar pesos al nuevo modelo\n",
    "loaded_model.load_weights(\"./h_fives/\"+name+\".h5\")\n",
    "print(\"Cargado modelo desde disco.\")\n",
    " \n",
    "# Compilar modelo cargado y listo para usar.\n",
    "loaded_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "y_predicted_exp = loaded_model.predict(x_test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de pruebas: 40\n",
      "Cantidad total de aciertos: 39\n",
      "Porcentaje de aciertos: 97.5%\n",
      "[4, 0, 0, 2, 3, 5, 1, 2, 5, 5, 5, 4, 2, 0, 2, 4, 4, 4, 2, 5, 1, 4, 1, 4, 0, 5, 3, 1, 1, 2, 2, 0, 1, 0, 2, 5, 2, 5, 5, 3]\n",
      "[4, 0, 0, 2, 3, 5, 1, 2, 5, 5, 5, 4, 2, 0, 2, 4, 4, 4, 2, 5, 1, 4, 1, 4, 0, 5, 3, 1, 3, 2, 2, 0, 1, 0, 2, 5, 2, 5, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "stadistics(convert_at_type_array(y_predicted_exp),convert_at_type_array(y_t.to_numpy()))\n",
    "\n",
    "print(convert_at_type_array(y_predicted_exp))\n",
    "print(convert_at_type_array(y_t.to_numpy())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>A_M</th>\n",
       "      <th>Color</th>\n",
       "      <th>Spectral_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21020</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.01120</td>\n",
       "      <td>11.520</td>\n",
       "      <td>Blue</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2935</td>\n",
       "      <td>0.00087</td>\n",
       "      <td>0.09320</td>\n",
       "      <td>16.880</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16390</td>\n",
       "      <td>1278.00000</td>\n",
       "      <td>5.68000</td>\n",
       "      <td>-3.320</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3628</td>\n",
       "      <td>0.00550</td>\n",
       "      <td>0.39300</td>\n",
       "      <td>10.480</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3496</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>0.33600</td>\n",
       "      <td>14.940</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3342</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.30700</td>\n",
       "      <td>11.870</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17140</td>\n",
       "      <td>883.00000</td>\n",
       "      <td>5.65300</td>\n",
       "      <td>-2.640</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24490</td>\n",
       "      <td>248490.00000</td>\n",
       "      <td>1134.50000</td>\n",
       "      <td>-8.240</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11000</td>\n",
       "      <td>170000.00000</td>\n",
       "      <td>1779.00000</td>\n",
       "      <td>-9.900</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24020</td>\n",
       "      <td>0.00159</td>\n",
       "      <td>0.01270</td>\n",
       "      <td>10.550</td>\n",
       "      <td>Blue</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23678</td>\n",
       "      <td>244290.00000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>-6.270</td>\n",
       "      <td>Blue</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16790</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>0.01210</td>\n",
       "      <td>12.870</td>\n",
       "      <td>Blue</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9700</td>\n",
       "      <td>74.00000</td>\n",
       "      <td>2.89000</td>\n",
       "      <td>0.160</td>\n",
       "      <td>Whitish</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2983</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.09400</td>\n",
       "      <td>16.090</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3218</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.11000</td>\n",
       "      <td>20.020</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12893</td>\n",
       "      <td>184000.00000</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>-6.340</td>\n",
       "      <td>Blue</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13720</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.00892</td>\n",
       "      <td>12.970</td>\n",
       "      <td>white</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3650</td>\n",
       "      <td>310000.00000</td>\n",
       "      <td>1324.00000</td>\n",
       "      <td>-7.790</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3541</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>0.25600</td>\n",
       "      <td>14.330</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33300</td>\n",
       "      <td>240000.00000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>Blue</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2799</td>\n",
       "      <td>0.00180</td>\n",
       "      <td>0.16000</td>\n",
       "      <td>14.790</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3553</td>\n",
       "      <td>145000.00000</td>\n",
       "      <td>1324.00000</td>\n",
       "      <td>-11.030</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8927</td>\n",
       "      <td>239000.00000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>-7.340</td>\n",
       "      <td>Blue</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3826</td>\n",
       "      <td>200000.00000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>-6.930</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3068</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>16.120</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3150</td>\n",
       "      <td>0.00880</td>\n",
       "      <td>0.35000</td>\n",
       "      <td>11.940</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2650</td>\n",
       "      <td>0.00069</td>\n",
       "      <td>0.11000</td>\n",
       "      <td>17.450</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21904</td>\n",
       "      <td>748490.00000</td>\n",
       "      <td>1130.00000</td>\n",
       "      <td>-7.670</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20120</td>\n",
       "      <td>4720.00000</td>\n",
       "      <td>6.78000</td>\n",
       "      <td>-3.400</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>12749</td>\n",
       "      <td>332520.00000</td>\n",
       "      <td>76.00000</td>\n",
       "      <td>-7.020</td>\n",
       "      <td>Blue</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>19400</td>\n",
       "      <td>10920.00000</td>\n",
       "      <td>6.03000</td>\n",
       "      <td>-3.080</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>26140</td>\n",
       "      <td>14520.00000</td>\n",
       "      <td>5.49000</td>\n",
       "      <td>-3.800</td>\n",
       "      <td>Blue-white</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3146</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.09320</td>\n",
       "      <td>16.920</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3399</td>\n",
       "      <td>117000.00000</td>\n",
       "      <td>1486.00000</td>\n",
       "      <td>-10.920</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2935</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.11600</td>\n",
       "      <td>18.890</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3340</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>0.24000</td>\n",
       "      <td>13.070</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>23095</td>\n",
       "      <td>347820.00000</td>\n",
       "      <td>86.00000</td>\n",
       "      <td>-5.905</td>\n",
       "      <td>Blue</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3225</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.12100</td>\n",
       "      <td>19.630</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.13000</td>\n",
       "      <td>16.050</td>\n",
       "      <td>Red</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Temperature             L           R     A_M       Color Spectral_Class\n",
       "0         21020       0.00150     0.01120  11.520        Blue              B\n",
       "1          2935       0.00087     0.09320  16.880         Red              M\n",
       "2         16390    1278.00000     5.68000  -3.320  Blue-white              B\n",
       "3          3628       0.00550     0.39300  10.480         Red              M\n",
       "4          3496       0.00125     0.33600  14.940         Red              M\n",
       "5          3342       0.00150     0.30700  11.870         Red              M\n",
       "6         17140     883.00000     5.65300  -2.640  Blue-white              B\n",
       "7         24490  248490.00000  1134.50000  -8.240  Blue-white              B\n",
       "8         11000  170000.00000  1779.00000  -9.900  Blue-white              B\n",
       "9         24020       0.00159     0.01270  10.550        Blue              B\n",
       "10        23678  244290.00000    35.00000  -6.270        Blue              O\n",
       "11        16790       0.00140     0.01210  12.870        Blue              B\n",
       "12         9700      74.00000     2.89000   0.160     Whitish              B\n",
       "13         2983       0.00024     0.09400  16.090         Red              M\n",
       "14         3218       0.00054     0.11000  20.020         Red              M\n",
       "15        12893  184000.00000    36.00000  -6.340        Blue              O\n",
       "16        13720       0.00018     0.00892  12.970       white              F\n",
       "17         3650  310000.00000  1324.00000  -7.790         Red              M\n",
       "18         3541       0.00130     0.25600  14.330         Red              M\n",
       "19        33300  240000.00000    12.00000  -6.500        Blue              B\n",
       "20         2799       0.00180     0.16000  14.790         Red              M\n",
       "21         3553  145000.00000  1324.00000 -11.030         Red              M\n",
       "22         8927  239000.00000    35.00000  -7.340        Blue              O\n",
       "23         3826  200000.00000    19.00000  -6.930         Red              M\n",
       "24         3068       0.00240     0.17000  16.120         Red              M\n",
       "25         3150       0.00880     0.35000  11.940         Red              M\n",
       "26         2650       0.00069     0.11000  17.450         Red              M\n",
       "27        21904  748490.00000  1130.00000  -7.670  Blue-white              B\n",
       "28        20120    4720.00000     6.78000  -3.400  Blue-white              B\n",
       "29        12749  332520.00000    76.00000  -7.020        Blue              O\n",
       "30        19400   10920.00000     6.03000  -3.080  Blue-white              B\n",
       "31        26140   14520.00000     5.49000  -3.800  Blue-white              B\n",
       "32         3146       0.00015     0.09320  16.920         Red              M\n",
       "33         3399  117000.00000  1486.00000 -10.920         Red              M\n",
       "34         2935       0.00014     0.11600  18.890         Red              M\n",
       "35         3340       0.00380     0.24000  13.070         Red              M\n",
       "36        23095  347820.00000    86.00000  -5.905        Blue              O\n",
       "37         3225       0.00076     0.12100  19.630         Red              M\n",
       "38         2700       0.00018     0.13000  16.050         Red              M"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_comp = pd.read_csv(\"test_ds.csv\")\n",
    "stars_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_variables_x_test(stars):\n",
    "    x_test = stars.iloc[:,0:4]\n",
    "    return x_test\n",
    "stars_comp = select_variables_x_test(stars_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 3, 1, 1, 1, 3, 5, 5, 2, 4, 2, 3, 0, 0, 4, 2, 5, 1, 4, 0, 5, 4, 4, 0, 1, 0, 5, 3, 4, 3, 3, 0, 5, 0, 1, 4, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "y_predicted_comp = loaded_model.predict(stars_comp).round()\n",
    "y_predicted_comp = convert_at_type_array(y_predicted_comp)\n",
    "\n",
    "print(y_predicted_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = range(1,len(y_predicted_comp)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Type\n",
       "Id      \n",
       "1      2\n",
       "2      0\n",
       "3      3\n",
       "4      1\n",
       "5      1\n",
       "6      1\n",
       "7      3\n",
       "8      5\n",
       "9      5\n",
       "10     2\n",
       "11     4\n",
       "12     2\n",
       "13     3\n",
       "14     0\n",
       "15     0\n",
       "16     4\n",
       "17     2\n",
       "18     5\n",
       "19     1\n",
       "20     4\n",
       "21     0\n",
       "22     5\n",
       "23     4\n",
       "24     4\n",
       "25     0\n",
       "26     1\n",
       "27     0\n",
       "28     5\n",
       "29     3\n",
       "30     4\n",
       "31     3\n",
       "32     3\n",
       "33     0\n",
       "34     5\n",
       "35     0\n",
       "36     1\n",
       "37     4\n",
       "38     0\n",
       "39     0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution = pd.DataFrame()\n",
    "solution[\"Id\"] = indexs\n",
    "solution[\"Type\"] = y_predicted_comp\n",
    "solution.set_index(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.csv\n",
    "#solution.set_index(\"Id\").to_csv(\"submission.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
